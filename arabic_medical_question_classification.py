# -*- coding: utf-8 -*-
"""

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1k-bC36w6435fXS3ieD8dn9KhCTUAWaK3


"""

import re
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

import nltk
from nltk.corpus import stopwords

import tensorflow as tf
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.layers import (
    Embedding, Conv1D, GlobalMaxPooling1D, LSTM, Bidirectional,
    Dense, Dropout, Input, Concatenate, BatchNormalization, SpatialDropout1D
)
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping

from sklearn.preprocessing import LabelEncoder
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV
from sklearn.ensemble import RandomForestClassifier
from sklearn.naive_bayes import MultinomialNB, ComplementNB
from sklearn.svm import LinearSVC
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import (
    accuracy_score, classification_report, confusion_matrix
)
from sklearn.utils.class_weight import compute_class_weight
from scipy.stats import randint

from datasets import load_dataset
import plotly.express as px

"""## ØªØ­Ù…ÙŠÙ„ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""

dataset_name = "Ahmed-Selem/Shifaa_Arabic_Medical_Consultations"

try:
    dataset = load_dataset(dataset_name)
    print(f"Successfully downloaded dataset: {dataset_name}")
    print(dataset)
except Exception as e:
    print(f"Error downloading dataset {dataset_name}: {e}")

"""## ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ù„Ù‰ DataFrame

Ù‡Ø°Ø§ Ø§Ù„ØªØ­ÙˆÙŠÙ„ ÙŠØ³Ù‡Ù„ Ø¹Ù„ÙŠÙ†Ø§:
- Ø§Ø³ØªÙƒØ´Ø§Ù Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (EDA)
- ØªÙ†ÙÙŠØ° Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø³Ø¨Ù‚Ø©
- ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© ÙˆØ§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù†ØµÙŠØ©


"""

df = dataset['train'].to_pandas()
print("Dataset converted to pandas DataFrame. Displaying the first 5 rows:")
display(df.head())

# Extract the main category from 'Hierarchical Diagnosis'
df['Main Category'] = df['Hierarchical Diagnosis'].apply(lambda x: x.split(' - ')[0] if isinstance(x, str) and ' - ' in x else x)

print("Added 'main category' column. Displaying the first 5 rows with the new column:")
display(df.head())

"""## Ø§Ø³ØªÙƒØ´Ø§Ù Ø¨Ù†ÙŠØ© Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
ÙÙŠ Ù‡Ø°Ù‡ Ø§Ù„Ø®Ø·ÙˆØ© Ù†Ù‚ÙˆÙ… Ø¨ÙØ­Øµ Ø§Ù„Ø¨Ù†ÙŠØ© Ø§Ù„Ø¹Ø§Ù…Ø© Ù„Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ø®Ù„Ø§Ù„:
- Ù…Ø¹Ø±ÙØ© Ø¹Ø¯Ø¯ Ø§Ù„ØµÙÙˆÙ (Ø§Ù„Ø¹ÙŠÙ†Ø§Øª)
- Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© (Ø§Ù„Ù…ÙŠØ²Ø§Øª)
- Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…ØªÙˆÙØ±Ø©


"""

print("Number of rows and columns in the dataset:")
print(df.shape)
print("\nColumns in the dataset:")
print(df.columns.tolist())

"""Ù†Ù„Ø§Ø­Ø¸ Ø£Ù† Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ 84,422 Ø¹ÙŠÙ†Ø© Ùˆ 8 Ø£Ø¹Ù…Ø¯Ø©

## Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø©
"""

print("Number of missing values in each column:")
print(df.isnull().sum())

"""ØªÙØ¸Ù‡Ø± Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø£Ù† Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø®Ø§Ù„ÙŠØ© Ù…Ù† Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø©  
Ù…Ù…Ø§ ÙŠØ¯Ù„ Ø¹Ù„Ù‰ Ø¬ÙˆØ¯Ø© Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆÙŠØºÙ†ÙŠÙ†Ø§ Ø¹Ù† ØªÙ†ÙÙŠØ° Ø®Ø·ÙˆØ§Øª Ù…Ø¹Ø§Ù„Ø¬Ø© Ø®Ø§ØµØ© Ø¨Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ù†Ø§Ù‚ØµØ©.

## ØªÙˆØ²ÙŠØ¹ Ø§Ù„ÙØ¦Ø§Øª Ø§Ù„Ø·Ø¨ÙŠØ© (Main Category)
"""

print("Distribution of Main Category:")
print(df['Main Category'].value_counts())

"""Ù†Ù„Ø§Ø­Ø¸ Ø£Ù† Ø¨Ø¹Ø¶ Ø§Ù„ØªØ®ØµØµØ§Øª Ø§Ù„Ø·Ø¨ÙŠØ© ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø¹Ø¯Ø¯ ÙƒØ¨ÙŠØ± Ù…Ù† Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ù…Ø«Ù„:
- Ø£Ù…Ø±Ø§Ø¶ Ø§Ù„Ù†Ø³Ø§Ø¡ ÙˆØ§Ù„ÙˆÙ„Ø§Ø¯Ø©
- Ø£Ù…Ø±Ø§Ø¶ Ø§Ù„Ø¨Ø§Ø·Ù†ÙŠØ© ÙˆØ§Ù„ØµØ¯Ø±

ÙÙŠ Ø­ÙŠÙ† Ø£Ù† ØªØ®ØµØµØ§Øª Ø£Ø®Ø±Ù‰ ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø¹Ø¯Ø¯ Ø£Ù‚Ù„ Ù…Ù† Ø§Ù„Ø¹ÙŠÙ†Ø§Øª Ù…Ø«Ù„:
- Ø§Ù„Ø·Ø¨ Ø§Ù„Ø¨Ø¯ÙŠÙ„
- Ø§Ù„Ø¬Ø±Ø§Ø­Ø© Ø§Ù„Ø¹Ø§Ù…Ø© ÙˆØ§Ù„ØªØ¬Ù…ÙŠÙ„

ÙˆÙ‡Ø°Ø§ ÙŠØ´ÙŠØ± Ø¥Ù„Ù‰ ÙˆØ¬ÙˆØ¯ Ø¹Ø¯Ù… ØªÙˆØ§Ø²Ù† Ù†Ø³Ø¨ÙŠ Ø¨ÙŠÙ† Ø§Ù„ÙØ¦Ø§Øª

## Ø§Ù„ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ù†Ø³Ø¨ÙŠ Ù„Ù„ÙØ¦Ø§Øª Ø§Ù„Ø·Ø¨ÙŠØ©
"""

print("Percentage distribution of Main Category:")
print(df['Main Category'].value_counts(normalize=True) * 100)

"""Ù†Ù„Ø§Ø­Ø¸ Ø£Ù† Ø£ÙƒØ¨Ø± ÙØ¦Ø© ØªÙ…Ø«Ù„ Ø­ÙˆØ§Ù„ÙŠ 17% Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§ØªØŒ  
Ø¨ÙŠÙ†Ù…Ø§ Ø¨Ø¹Ø¶ Ø§Ù„ÙØ¦Ø§Øª ØªÙ…Ø«Ù„ Ø£Ù‚Ù„ Ù…Ù† 1% ÙÙ‚Ø·.

Ù‡Ø°Ø§ Ø§Ù„ØªÙØ§ÙˆØª ÙŠØ¤ÙƒØ¯ Ø¶Ø±ÙˆØ±Ø© Ø§Ù„Ø§Ù†ØªØ¨Ø§Ù‡ Ø¥Ù„Ù‰ Ù…Ø´ÙƒÙ„Ø© **Class Imbalance** Ø£Ø«Ù†Ø§Ø¡ Ù…Ø±Ø­Ù„Ø© Ø§Ù„Ù†Ù…Ø°Ø¬Ø©.

## ØªØ­Ù„ÙŠÙ„ Ø·ÙˆÙ„ Ù†ØµÙˆØµ Ø§Ù„Ø£Ø³Ø¦Ù„Ø©
ÙÙŠ Ù‡Ø°Ù‡ Ø§Ù„Ø®Ø·ÙˆØ© Ù†Ù‚ÙˆÙ… Ø¨ØªØ­Ù„ÙŠÙ„ Ø·ÙˆÙ„ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ø·Ø¨ÙŠØ© Ù…Ù† Ø­ÙŠØ«:
- Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ø­Ø§Ø±Ù (Character Length)
- Ø¹Ø¯Ø¯ Ø§Ù„ÙƒÙ„Ù…Ø§Øª (Word Length)
"""

df['question_char_length'] = df['Question'].apply(lambda x: len(str(x)))
df['question_word_length'] = df['Question'].apply(lambda x: len(str(x).split()))
print("Added character length and word length for each question.")
display(df[['Question', 'question_char_length', 'question_word_length']].head())

"""Ù†Ù„Ø§Ø­Ø¸ ÙˆØ¬ÙˆØ¯ ØªØ¨Ø§ÙŠÙ† ÙÙŠ Ø£Ø·ÙˆØ§Ù„ Ø§Ù„Ø£Ø³Ø¦Ù„Ø©ØŒ  
Ø­ÙŠØ« ØªØªØ±Ø§ÙˆØ­ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø¨ÙŠÙ† Ù‚ØµÙŠØ±Ø© Ù†Ø³Ø¨ÙŠÙ‹Ø§ ÙˆØ£Ø®Ø±Ù‰ Ø£Ø·ÙˆÙ„ ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø´Ø±Ø­ ØªÙØµÙŠÙ„ÙŠ Ù„Ù„Ø­Ø§Ù„Ø© Ø§Ù„Ø·Ø¨ÙŠØ©

## Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠ Ù„Ø£Ø·ÙˆØ§Ù„ Ù†ØµÙˆØµ Ø§Ù„Ø£Ø³Ø¦Ù„Ø©
"""

print("Character length statistics:")
display(df['question_char_length'].describe())
print("Word length statistics:")
display(df['question_word_length'].describe())

"""Ù†Ù„Ø§Ø­Ø¸ Ø£Ù†:
- Ù…ØªÙˆØ³Ø· Ø·ÙˆÙ„ Ø§Ù„Ø³Ø¤Ø§Ù„ ÙŠÙ‚Ø§Ø±Ø¨ 587 Ù…Ø­Ø±ÙÙ‹Ø§ Ùˆ 105 ÙƒÙ„Ù…Ø©
- Ù†ØµÙ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© ØªÙ‚Ø±ÙŠØ¨Ù‹Ø§ ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø£Ù‚Ù„ Ù…Ù† 465 Ù…Ø­Ø±ÙÙ‹Ø§ Ùˆ 83 ÙƒÙ„Ù…Ø©
- ØªÙˆØ¬Ø¯ Ø£Ø³Ø¦Ù„Ø© Ø·ÙˆÙŠÙ„Ø© Ø¬Ø¯Ù‹Ø§ ØªØµÙ„ Ø¥Ù„Ù‰ Ø£ÙƒØ«Ø± Ù…Ù† 1200 ÙƒÙ„Ù…Ø© ÙˆÙ‚Ø±Ø§Ø¨Ø© 7000 Ù…Ø­Ø±Ù

ÙŠØ´ÙŠØ± Ø°Ù„Ùƒ Ø¥Ù„Ù‰ ÙˆØ¬ÙˆØ¯ ØªÙØ§ÙˆØª ÙƒØ¨ÙŠØ± ÙÙŠ Ø£Ø·ÙˆØ§Ù„ Ø§Ù„Ø£Ø³Ø¦Ù„Ø©

## Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ù…ÙƒØ±Ø±Ø©
"""

duplicate_count = df['Question'].duplicated().sum()
print(f"Number of duplicated questions: {duplicate_count}")

"""ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ 29,212 Ø³Ø¤Ø§Ù„Ø§ Ù…ÙƒØ±Ø±Ø§ØŒ  
ÙˆÙ‡Ùˆ Ø¹Ø¯Ø¯ ÙƒØ¨ÙŠØ± Ù†Ø³Ø¨ÙŠØ§ Ù…Ù‚Ø§Ø±Ù†Ø© Ø¨Ø­Ø¬Ù… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ÙƒÙ„ÙŠ.

## ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ù…ØªØ·Ø±ÙØ© (Ù‚ØµÙŠØ±Ø© Ø¬Ø¯Ù‹Ø§ ÙˆØ·ÙˆÙŠÙ„Ø© Ø¬Ø¯Ù‹Ø§)
Ù„ÙÙ‡Ù… Ø·Ø¨ÙŠØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ø´ÙƒÙ„ Ø£Ø¹Ù…Ù‚ØŒ Ù†Ù‚ÙˆÙ… Ø¨Ø¹Ø±Ø¶ Ø£Ù…Ø«Ù„Ø© Ø¹Ù„Ù‰:
- Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ù‚ØµÙŠØ±Ø© Ø¬Ø¯Ù‹Ø§ (Ø£Ù‚Ù„ Ù…Ù† 3 ÙƒÙ„Ù…Ø§Øª)
- Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ø·ÙˆÙŠÙ„Ø© Ø¬Ø¯Ù‹Ø§ (Ø£ÙƒØ«Ø± Ù…Ù† 50 ÙƒÙ„Ù…Ø©)
"""

print("Examples of very short questions (less than 3 words):")
display(df[df['question_word_length'] < 3].head())
print("\nExamples of very long questions (more than 50 words):")
display(df[df['question_word_length'] > 50].head())

"""Ù†Ù„Ø§Ø­Ø¸ Ø£Ù† Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ù‚ØµÙŠØ±Ø© Ø¬Ø¯Ø§ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø© ÙØ¹Ù„ÙŠÙ‹Ø§ØŒ  
Ø¨ÙŠÙ†Ù…Ø§ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ø·ÙˆÙŠÙ„Ø© Ø´Ø§Ø¦Ø¹Ø© Ù†Ø³Ø¨ÙŠÙ‹Ø§ØŒ ÙˆØºØ§Ù„Ø¨Ù‹Ø§ Ù…Ø§ ØªØªØ¶Ù…Ù† ÙˆØµÙÙ‹Ø§ ØªÙØµÙŠÙ„ÙŠÙ‹Ø§ Ù„Ù„Ø­Ø§Ù„Ø© Ø§Ù„Ø·Ø¨ÙŠØ©.
"""

fig = px.histogram(
    df,
    x='question_word_length',
    nbins=50,
    title='Distribution of Question Lengths (in words)',
    labels={'question_word_length': 'Number of words in question', 'count': 'Number of questions'},
    color_discrete_sequence=['skyblue']
)

fig.update_layout(
    bargap=0.05,
    xaxis=dict(title='Number of words in question'),
    yaxis=dict(title='Number of questions'),
    template='plotly_white'
)

fig.show()

"""#Ø¹Ø¯Ø¯ Ø§Ù„ÙØ¦Ø§Øª Ø¯Ø§Ø®Ù„ Hierarchical Diagnosis


"""

print("Number of unique hierarchical diagnoses:")
print(df['Hierarchical Diagnosis'].nunique())
print("\nExamples of diagnosis values:")
display(df['Hierarchical Diagnosis'].head(10))

"""Ù†Ù„Ø§Ø­Ø¸ ÙˆØ¬ÙˆØ¯ 585 ØªØµÙ†ÙŠÙØ§ Ù‡Ø±Ù…ÙŠØ§ Ù…Ø®ØªÙ„ÙØ§  
Ù…Ù…Ø§ ÙŠØ¹ÙƒØ³ Ø¯Ø±Ø¬Ø© Ø¹Ø§Ù„ÙŠØ© Ù…Ù† Ø§Ù„ØªÙØµÙŠÙ„ ÙÙŠ Ø§Ù„ØªØ´Ø®ÙŠØµ Ø§Ù„Ø·Ø¨ÙŠ.

## ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªØµÙ†ÙŠÙØ§Øª Ø§Ù„Ø·Ø¨ÙŠØ© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© (Main Category)
"""

print("Number of unique Main Category:")
print(df['Main Category'].nunique())
print("All unique Main Categories:")
display(df['Main Category'].unique())

"""Ù†Ù„Ø§Ø­Ø¸ Ø£Ù† Ø¹Ø¯Ø¯ Ø§Ù„ÙØ¦Ø§Øª Ø§Ù„Ø·Ø¨ÙŠØ© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ù‡Ùˆ 16 ÙØ¦Ø© ÙÙ‚Ø·  
ÙˆÙ‡Ùˆ Ø¹Ø¯Ø¯ Ù…Ù†Ø§Ø³Ø¨ Ù„Ø¨Ù†Ø§Ø¡ Ù†Ù…Ø§Ø°Ø¬ ØªØµÙ†ÙŠÙ ÙØ¹Ø§Ù„Ø© ÙˆÙ…Ø³ØªÙ‚Ø±Ø©.


"""

category_counts = df['Main Category'].value_counts().reset_index()
category_counts.columns = ['Main Category', 'Count']
fig = px.bar(
    category_counts,
    x='Main Category',
    y='Count',
    title='Distribution of Main Categories',
    text='Count',
    color='Count',
    color_continuous_scale='Viridis')
fig.update_layout(
    xaxis_title="Main Category",
    yaxis_title="Number of Questions",
    xaxis_tickangle=-45)
fig.show()

"""## Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ù…ÙƒØ±Ø±Ø©
Ø§Ù„Ù‡Ø¯Ù Ù…Ù† Ù‡Ø°Ù‡ Ø§Ù„Ø®Ø·ÙˆØ© Ù‡Ùˆ:
- ØªÙ‚Ù„ÙŠÙ„ Ø§Ù„ØªØ­ÙŠØ² ÙÙŠ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
- Ù…Ù†Ø¹ ØªÙƒØ±Ø§Ø± Ù†ÙØ³ Ø§Ù„Ø¹ÙŠÙ†Ø© ÙÙŠ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ ÙˆØ§Ù„ØªÙ‚ÙŠÙŠÙ…
- ØªØ­Ø³ÙŠÙ† ØªØ¹Ù…ÙŠÙ… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
"""

def remove_duplicates(df):
    before = len(df)
    df = df.drop_duplicates(subset='Question', keep='first')
    after = len(df)
    print(f"Removed {before - after} duplicated questions.")
    return df

df = remove_duplicates(df)

"""ØªÙ…Øª Ø¥Ø²Ø§Ù„Ø© 29,212 Ø³Ø¤Ø§Ù„Ø§ Ù…ÙƒØ±Ø±Ø§"""

category_counts_cleaned = df['Main Category'].value_counts().reset_index()
category_counts_cleaned.columns = ['Main Category', 'Count']
fig = px.bar(
    category_counts_cleaned,
    x='Main Category',
    y='Count',
    title='Distribution of Main Categories (After Removing Duplicates)',
    text='Count',
    color='Count',
    color_continuous_scale='Viridis')
fig.update_layout(
    xaxis_title="Main Category",
    yaxis_title="Number of Questions",
    xaxis_tickangle=-45)
fig.show()

"""## ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ø·Ø¨ÙŠØ©

ÙÙŠ Ù‡Ø°Ù‡ Ø§Ù„Ø®Ø·ÙˆØ© Ù†Ù‚ÙˆÙ… Ø¨ØªÙ†Ø¸ÙŠÙ Ù†ØµÙˆØµ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ø·Ø¨ÙŠØ© Ù…Ù† Ø§Ù„Ø¹Ù†Ø§ØµØ± ØºÙŠØ± Ø§Ù„Ù…ÙÙŠØ¯Ø©ØŒ Ù…Ø«Ù„:
- Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠØ©
- Ø§Ù„Ø±Ù…ÙˆØ² Ø§Ù„Ø®Ø§ØµØ© ØºÙŠØ± Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©
- Ø§Ù„ØªÙƒØ±Ø§Ø± ØºÙŠØ± Ø§Ù„Ø¶Ø±ÙˆØ±ÙŠ Ù„Ù„ÙØ±Ø§ØºØ§Øª

ÙŠÙ‡Ø¯Ù Ù‡Ø°Ø§ Ø§Ù„ØªÙ†Ø¸ÙŠÙ Ø¥Ù„Ù‰ ØªÙ‚Ù„ÙŠÙ„ Ø§Ù„Ø¶Ø¬ÙŠØ¬ ÙˆØªØ­Ø³ÙŠÙ† Ø¬ÙˆØ¯Ø© ØªÙ…Ø«ÙŠÙ„ Ø§Ù„Ù†Øµ.

"""

def clean_medical_text(text):
    if not isinstance(text, str):
        return text
    text = re.sub(r"http\S+|www.\S+", " ", text)
    text = re.sub(r"[^\w\s\u0600-\u06FF0-9]", " ", text)
    text = re.sub(r"\s+", " ", text).strip()
    return text

df['clean_question'] = df['Question'].apply(clean_medical_text)

"""## ØªÙˆØ­ÙŠØ¯ Ø§Ù„ÙƒØªØ§Ø¨Ø© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© (Normalization)

Ù†Ù‚ÙˆÙ… Ø¨ØªÙˆØ­ÙŠØ¯ Ù‡Ø°Ù‡ Ø§Ù„Ø£Ø´ÙƒØ§Ù„ Ø¥Ù„Ù‰ ØµÙŠØºØ© ÙˆØ§Ø­Ø¯Ø©.

ØªØ´Ù…Ù„ Ù‡Ø°Ù‡ Ø§Ù„Ø®Ø·ÙˆØ©:
- ØªÙˆØ­ÙŠØ¯ Ø§Ù„Ø£Ù„Ù(Ø£, Ø¥, Ø¢ â†’ Ø§)
- ØªØ­ÙˆÙŠÙ„ (Ù‰ â†’ ÙŠ)
- ØªØ­ÙˆÙŠÙ„ (Ø© â†’ Ù‡)
- Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªØ·ÙˆÙŠÙ„ (Ù€)

ÙŠØ³Ø§Ø¹Ø¯ Ø°Ù„Ùƒ ÙÙŠ:
- ØªÙ‚Ù„ÙŠÙ„ Ø­Ø¬Ù… Ø§Ù„Ù…ÙØ±Ø¯Ø§Øª
- ØªØ­Ø³ÙŠÙ† ØªÙ…Ø«ÙŠÙ„ Ø§Ù„ÙƒÙ„Ù…Ø§Øª
- Ø²ÙŠØ§Ø¯Ø© ÙƒÙØ§Ø¡Ø© Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ© ÙˆØ§Ù„Ø¹Ù…ÙŠÙ‚Ø©

"""

def normalize_arabic(text):
    text = re.sub("[Ø¥Ø£Ø¢Ø§]", "Ø§", text)
    text = re.sub("Ù‰", "ÙŠ", text)
    text = re.sub("Ø©", "Ù‡", text)
    text = re.sub("Ø¤", "Ùˆ", text)
    text = re.sub("Ø¦", "ÙŠ", text)
    text = re.sub("Ù€", "", text)
    return text

df['normalized_question'] = df['clean_question'].apply(normalize_arabic)
df[['clean_question','normalized_question']].head()

"""## Ø¥Ø²Ø§Ù„Ø© ÙƒÙ„Ù…Ø§Øª Ø§Ù„ØªÙˆÙ‚Ù

ÙƒÙ„Ù…Ø§Øª Ø§Ù„ØªÙˆÙ‚Ù Ù‡ÙŠ ÙƒÙ„Ù…Ø§Øª Ø´Ø§Ø¦Ø¹Ø© ÙÙŠ Ø§Ù„Ù„ØºØ© (Ù…Ø«Ù„: Ù…Ù†ØŒ Ø¥Ù„Ù‰ØŒ Ø¹Ù„Ù‰)  
ÙˆÙ„Ø§ ØªØ­Ù…Ù„ ØºØ§Ù„Ø¨Ù‹Ø§ Ù‚ÙŠÙ…Ø© Ø¯Ù„Ø§Ù„ÙŠØ© Ù…Ù‡Ù…Ø© Ù„Ø¹Ù…Ù„ÙŠØ© Ø§Ù„ØªØµÙ†ÙŠÙ.
"""

nltk.download('stopwords')
  arabic_stopwords = set(stopwords.words('arabic'))
  def remove_stopwords(text):
      words = text.split()
      words = [w for w in words if w not in arabic_stopwords]
      return " ".join(words)
  df['no_stopwords_question'] = df['normalized_question'].apply(remove_stopwords)

"""## Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ù‚ØµÙŠØ±Ø© Ø¬Ø¯Ù‹Ø§

Ø¨Ø¹Ø¶ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ù‚ØµÙŠØ±Ø© Ø¬Ø¯Ù‹Ø§ (Ø£Ù‚Ù„ Ù…Ù† 3 ÙƒÙ„Ù…Ø§Øª)  
Ù„Ø§ ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª ÙƒØ§ÙÙŠØ© Ù„ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø§Ø®ØªØµØ§Øµ Ø§Ù„Ø·Ø¨ÙŠ Ø¨Ø¯Ù‚Ø©.

Ù„Ø°Ù„Ùƒ Ù†Ù‚ÙˆÙ… Ø¨Ø­Ø°Ù Ù‡Ø°Ù‡ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ù…Ù† Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª.

"""

before = len(df)
df = df[df['no_stopwords_question'].apply(lambda x: len(x.split()) >= 3)]
after = len(df)
print(f"Removed {before - after} very short questions.")

"""ØªÙ…Øª Ø¥Ø²Ø§Ù„Ø© Ø³Ø¤Ø§Ù„ ÙˆØ§Ø­Ø¯ ÙÙ‚Ø·  
Ù…Ù…Ø§ ÙŠØ¯Ù„ Ø¹Ù„Ù‰ Ø£Ù† Ù…Ø¹Ø¸Ù… Ø§Ù„Ø£Ø³Ø¦Ù„Ø© ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ ÙˆØµÙ ÙƒØ§ÙÙ Ù„Ù„Ø­Ø§Ù„Ø© Ø§Ù„Ø·Ø¨ÙŠØ©.

## Ù‚Øµ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ø·ÙˆÙŠÙ„Ø©

Ù†Ø¸Ø±Ù‹Ø§ Ù„ÙˆØ¬ÙˆØ¯ Ø£Ø³Ø¦Ù„Ø© Ø·ÙˆÙŠÙ„Ø© Ø¬Ø¯Ù‹Ø§ØŒ  
Ù†Ù‚ÙˆÙ… Ø¨ØªØ­Ø¯ÙŠØ¯ Ø­Ø¯ Ø£Ù‚ØµÙ‰ Ù„Ø·ÙˆÙ„ Ø§Ù„Ø³Ø¤Ø§Ù„ Ø¨Ù€ 250 ÙƒÙ„Ù…Ø©.
"""

def trim_text(text, max_words=250):
    words = text.split()
    if len(words) > max_words:
        return " ".join(words[:max_words])
    return text
df['trimmed_question'] = df['no_stopwords_question'].apply(trim_text)

"""## ğŸ·ï¸ ØªØ±Ù…ÙŠØ² Ø§Ù„ÙØ¦Ø§Øª (Label Encoding)

Ø¨Ù…Ø§ Ø£Ù† Ø¹Ù…ÙˆØ¯(Main Category) Ø¹Ø¨Ø§Ø±Ø© Ø¹Ù† Ù†Øµ Ø¹Ø±Ø¨ÙŠØŒ
ÙØ¥Ù†Ù†Ø§ Ù†Ø­ØªØ§Ø¬ Ù„ØªØ­ÙˆÙŠÙ„Ù‡ Ø¥Ù„Ù‰ Ø£Ø±Ù‚Ø§Ù… Ø­ØªÙ‰ ØªØªÙ…ÙƒÙ† Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ù…Ù† Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹Ù‡.
"""

label_encoder = LabelEncoder()
df['label'] = label_encoder.fit_transform(df['Main Category'])
df[['Main Category','label']].head()

"""## ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ù„Ù‰ ØªØ¯Ø±ÙŠØ¨ ÙˆØªØ­Ù‚Ù‚ ÙˆØ§Ø®ØªØ¨Ø§Ø±

ÙÙŠ Ù‡Ø°Ù‡ Ø§Ù„Ø®Ø·ÙˆØ© Ù†Ù‚ÙˆÙ… Ø¨ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ù„Ù‰:
- 80% ØªØ¯Ø±ÙŠØ¨
- 10% ØªØ­Ù‚Ù‚ (Validation)
- 10% Ø§Ø®ØªØ¨Ø§Ø± (Test)

ÙŠØªÙ… Ø§Ù„ØªÙ‚Ø³ÙŠÙ… Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… **Stratified Sampling**  
Ù„Ø¶Ù…Ø§Ù† Ø§Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ù†ÙØ³ ØªÙˆØ²ÙŠØ¹ Ø§Ù„ÙØ¦Ø§Øª ÙÙŠ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø§Øª.

"""

train_df, temp_df = train_test_split(df, test_size=0.2, stratify=df['label'], random_state=42)
val_df, test_df = train_test_split(temp_df, test_size=0.5, stratify=temp_df['label'], random_state=42)
print(train_df.shape, val_df.shape, test_df.shape)

"""## ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª ÙˆØ§Ù„Ù…Ø®Ø±Ø¬Ø§Øª

- Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª (X): Ù†Øµ Ø§Ù„Ø³Ø¤Ø§Ù„ Ø¨Ø¹Ø¯ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© (`trimmed_question`)
- Ø§Ù„Ù…Ø®Ø±Ø¬Ø§Øª (y): Ø§Ù„ØªØµÙ†ÙŠÙ Ø§Ù„Ø·Ø¨ÙŠ Ø§Ù„Ù…Ø±Ù…Ù‘Ø² (`label`)

"""

X_train = train_df['trimmed_question']
X_val = val_df['trimmed_question']
X_test = test_df['trimmed_question']

y_train = train_df['label']
y_val = val_df['label']
y_test = test_df['label']

"""### ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†ØµÙˆØµ Ø¥Ù„Ù‰ TF-IDF Features

"""

tfidf = TfidfVectorizer(
    analyzer='word',
    ngram_range=(1, 2),
    min_df=2,
    max_df=0.90,
    max_features=50000,
    token_pattern=r"(?u)\b\w+\b",
    lowercase=False,
    stop_words=None
)
X_train_tfidf = tfidf.fit_transform(X_train)
X_val_tfidf = tfidf.transform(X_val)
X_test_tfidf = tfidf.transform(X_test)
print("X_train_tfidf shape:", X_train_tfidf.shape)
print("X_val_tfidf shape:  ", X_val_tfidf.shape)
print("X_test_tfidf shape: ", X_test_tfidf.shape)

"""###  ØªØ­Ù„ÙŠÙ„ Ø¨Ø¹Ø¶ Ù…ÙŠØ²Ø§Øª TF-IDF

"""

feature_names = tfidf.get_feature_names_out()
print("Number of features:", len(feature_names))
print(feature_names[:20])
row0 = X_train_tfidf[0]
nz = row0.nonzero()[1]
top_n = sorted([(i, row0[0, i]) for i in nz], key=lambda x: x[1], reverse=True)[:15]
for idx, val in top_n:
    print(feature_names[idx], "-->", val)

"""Ø¹Ù†Ø¯ Ø§Ø³ØªØ¹Ø±Ø§Ø¶ Ø¨Ø¹Ø¶ Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„Ø£Ø¹Ù„Ù‰ ÙˆØ²Ù†Ù‹Ø§ ÙÙŠ Ø£Ø­Ø¯ Ù†ØµÙˆØµ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ØŒ Ù„ÙˆØ­Ø¸ ÙˆØ¬ÙˆØ¯:

- Ø¹Ø¨Ø§Ø±Ø§Øª Ø·Ø¨ÙŠØ© Ø¯Ù„Ø§Ù„ÙŠØ© Ù…Ø«Ù„:
  - `Ø§Ø¹Ø§Ù†ÙŠ Ù…ØºØµ`
  - `Ù…ØºØµ Ø´Ø¯ÙŠØ¯`
  - `Ø´Ø±Ø¨ Ø§Ù„Ù„Ø¨Ù†`
- ÙˆØ¨Ø¹Ø¶ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø£Ùˆ Ø§Ù„Ø¹Ø¨Ø§Ø±Ø§Øª Ø§Ù„Ø¹Ø§Ù…Ø© Ù…Ø«Ù„:
  - `Ø°Ù„Ùƒ`
  - `ÙˆÙ‚Ø¯`

###  ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ Logistic Regression (Baseline)

ØªÙ… ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ **Logistic Regression** Ø¨Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠØ© Ù…Ø¹:

- `class_weight='balanced'`  
  Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¹Ø¯Ù… ØªÙˆØ§Ø²Ù† Ø§Ù„ÙØ¦Ø§Øª.
"""

logreg = LogisticRegression(
    max_iter=300,
    class_weight='balanced',
    solver='liblinear',
    n_jobs=-1
)
logreg.fit(X_train_tfidf, y_train)
train_pred = logreg.predict(X_train_tfidf)
val_pred = logreg.predict(X_val_tfidf)
test_pred = logreg.predict(X_test_tfidf)

print("Train Accuracy:", accuracy_score(y_train, train_pred))
print("Validation Accuracy:", accuracy_score(y_val, val_pred))
print("Test Accuracy:", accuracy_score(y_test, test_pred))

print("\n--- Validation Classification Report ---")
print(classification_report(y_val, val_pred))

print("\n--- Test Classification Report ---")
print(classification_report(y_test, test_pred))

"""**Ø§Ù„Ø§Ø¯Ø§Ø¡ Ø§Ù„Ø¹Ø§Ù… Ù„Ù„Ù†Ù…ÙˆØ°Ø¬**
| Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø© | Ø§Ù„Ø¯Ù‚Ø© (Accuracy) |
|--------|------------------|
| Training | 82.9% |
| Validation | 72.8% |
| Test | 72.7% |
**ØªØ­Ù„ÙŠÙ„:**
- Ø§Ù„ÙØ±Ù‚ Ø¨ÙŠÙ† Ø¯Ù‚Ø© Ø§Ù„ØªØ¯Ø±ÙŠØ¨ ÙˆØ¯Ù‚Ø© Ø§Ù„ØªØ­Ù‚Ù‚/Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± ÙŠØ´ÙŠØ± Ø¥Ù„Ù‰ Overfitting Ù…Ø­Ø¯ÙˆØ¯
- ØªÙ‚Ø§Ø±Ø¨ Ø¯Ù‚Ø© Ø§Ù„ØªØ­Ù‚Ù‚ ÙˆØ§Ù„Ø§Ø®ØªØ¨Ø§Ø± ÙŠØ¯Ù„ Ø¹Ù„Ù‰ Ø£Ù† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙŠØ¹Ù…Ù‘Ù… Ø¨Ø´ÙƒÙ„ Ø¬ÙŠØ¯ ÙˆÙ„Ø§ ÙŠØ­ÙØ¸ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙÙ‚Ø·.

`Class-wise Performance:`
Ø§Ù„ÙØ¦Ø§Øª Ø°Ø§Øª Ø§Ù„Ø¹ÙŠÙ†Ø§Øª Ø§Ù„ÙƒØ¨ÙŠØ±Ø© (Ù…Ø«Ù„ 1ØŒ 2ØŒ 3ØŒ 6ØŒ 8ØŒ 10ØŒ 11) Ø£Ø¸Ù‡Ø±Øª:
- Precision ÙˆRecall Ù…Ø±ØªÙØ¹ÙŠÙ†
- Ù‚ÙŠÙ… F1-score Ø¬ÙŠØ¯Ø© (0.74 â€“ 0.85)

Ø§Ù„ÙØ¦Ø© 10 Ù‡ÙŠ Ø§Ù„Ø£ÙØ¶Ù„ Ø£Ø¯Ø§Ø¡

F1 â‰ˆ 0.85 ÙÙŠ ÙƒÙ„ Ù…Ù† Validation ÙˆTest
â†’ ÙŠØ¯Ù„ Ø¹Ù„Ù‰ ØªÙ…ÙŠÙŠØ² Ù‚ÙˆÙŠ Ù„Ù„Ø³Ù…Ø§Øª Ø§Ù„Ù†ØµÙŠØ© Ø§Ù„Ø®Ø§ØµØ© Ø¨Ù‡Ø§.

`Impact of Class Imbalance:`

Ø¨Ø¹Ø¶ Ø§Ù„ÙØ¦Ø§Øª Ø°Ø§Øª Ø§Ù„Ø¯Ø¹Ù… Ø§Ù„Ù‚Ù„ÙŠÙ„ Ø¬Ø¯Ø§ (Ù…Ø«Ù„ 7ØŒ 12ØŒ 14ØŒ 15) Ø³Ø¬Ù„Øª:

- Recall Ù…Ù†Ø®ÙØ¶
- F1-score Ø¶Ø¹ÙŠÙ (< 0.30)

Ø±ØºÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù… class_weight='balanced'ØŒ Ù…Ø§ Ø²Ø§Ù„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙŠØ¹Ø§Ù†ÙŠ Ù…Ø¹ Ø§Ù„ÙØ¦Ø§Øª Ø§Ù„Ù†Ø§Ø¯Ø±Ø©.

`Macro vs Weighted Average:`

- Weighted F1 â‰ˆ 0.73
â†’ ÙŠØ¹ÙƒØ³ Ø£Ø¯Ø§Ø¡ Ø¬ÙŠØ¯Ø§ Ø¹Ù„Ù‰ Ø§Ù„ÙØ¦Ø§Øª Ø§Ù„Ø£ÙƒØ«Ø± Ø´ÙŠÙˆØ¹Ù‹Ø§.

- Macro F1 â‰ˆ 0.59
â†’ ÙŠÙƒØ´Ù Ø§Ù„ØªÙØ§ÙˆØª ÙÙŠ Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø¨ÙŠÙ† Ø§Ù„ÙØ¦Ø§ØªØŒ Ø®Ø§ØµØ© Ø§Ù„ÙØ¦Ø§Øª Ø§Ù„ØµØºÙŠØ±Ø©.

Ø§Ù„ÙØ±Ù‚ Ø¨ÙŠÙ†Ù‡Ù…Ø§ ÙŠØ¤ÙƒØ¯ Ø£Ù† Ø¹Ø¯Ù… ØªÙˆØ§Ø²Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙŠØ¤Ø«Ø± Ø¹Ù„Ù‰ Ø§Ù„ØªÙ‚ÙŠÙŠÙ… Ø§Ù„ÙƒÙ„ÙŠ.

` Validation vs Test Consistency:`

Ø§Ù„ØªØ´Ø§Ø¨Ù‡ Ø§Ù„ÙƒØ¨ÙŠØ± Ø¨ÙŠÙ† ØªÙ‚Ø§Ø±ÙŠØ± Validation ÙˆTest:

ÙŠØ¯Ù„ Ø¹Ù„Ù‰ Ø£Ù† Ø¹Ù…Ù„ÙŠØ© Ø§Ù„ØªÙ‚Ø³ÙŠÙ… ØµØ­ÙŠØ­Ø©

ÙˆÙ„Ø§ ÙŠÙˆØ¬Ø¯ ØªØ³Ø±ÙŠØ¨ Ø¨ÙŠØ§Ù†Ø§Øª (Data Leakage)

#Confusion matrix :
"""

cm_test = confusion_matrix(y_test, test_pred)
print(f"Confusion matrix for test data (Shape: {cm_test.shape})")

plt.figure(figsize=(15, 13))
sns.heatmap(cm_test,
            annot=False,
            fmt='d',
            cmap='Blues',
            cbar_kws={'label': 'Number of samples'},
            square=True)

plt.title('Confusion Matrix - LogisticRegression Model (Test Data)',
          fontsize=16, fontweight='bold', pad=20)
plt.xlabel('Predicted Label', fontsize=14)
plt.ylabel('True Label', fontsize=14)
plt.tight_layout()
plt.show()

def calculate_class_accuracy(cm, class_names):
    class_accuracies = []

    for i, class_name in enumerate(class_names):
        correct = cm[i, i]
        total = cm[i, :].sum()
        accuracy = (correct / total * 100) if total > 0 else 0

        class_accuracies.append({
            'Class': class_name,
            'Accuracy_%': accuracy,
            'Correct': correct,
            'Total': total,
            'Errors': total - correct
        })

    accuracy_df = pd.DataFrame(class_accuracies)
    accuracy_df = accuracy_df.sort_values('Accuracy_%')

    return accuracy_df

accuracy_df = calculate_class_accuracy(cm_test, class_names)

low_accuracy_classes = accuracy_df[accuracy_df['Accuracy_%'] < 60]['Class'].tolist()
low_accuracy_indices = [np.where(class_names == cls)[0][0] for cls in low_accuracy_classes]

if low_accuracy_indices:
    cm_problematic = cm_test[low_accuracy_indices][:, low_accuracy_indices]

    plt.figure(figsize=(10, 8))
    sns.heatmap(cm_problematic,
                annot=True,
                fmt='d',
                cmap='Reds',
                xticklabels=low_accuracy_classes,
                yticklabels=low_accuracy_classes)

    plt.title('Confusion Matrix for Low-Accuracy Classes (< 60%)', fontsize=14, fontweight='bold')
    plt.xlabel('Predicted Label', fontsize=12)
    plt.ylabel('True Label', fontsize=12)
    plt.xticks(rotation=45, ha='right')
    plt.tight_layout()
    plt.show()

"""### ğŸ” Hyperparameter Tuning (Logistic Regression)
ÙÙŠ Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø±Ø­Ù„Ø© Ù‚Ù…Ù†Ø§ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… `GridSearchCV` Ù„Ø§Ø®ØªÙŠØ§Ø± Ø£ÙØ¶Ù„ Ù…Ø¹Ø§Ù…Ù„Ø§Øª (Hyperparameters)

Ø§Ù„Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ø§Ù„ØªÙŠ ØªÙ… Ø§Ø®ØªØ¨Ø§Ø±Ù‡Ø§:
- **C**: Ù„Ù„ØªØ­ÙƒÙ… Ø¨Ø¯Ø±Ø¬Ø© Ø§Ù„ØªÙ†Ø¸ÙŠÙ… (Regularization Strength)
- **penalty**: Ø§Ø³ØªØ®Ø¯Ù…Ù†Ø§ L2
- **solver**: Ø¬Ø±Ø¨Ù†Ø§ `lbfgs` Ùˆ `liblinea
"""

param_grid = {
    'C': [0.01, 0.1, 1, 5, 10],
    'penalty': ['l2'],
    'solver': ['lbfgs','liblinear']
}
grid = GridSearchCV(
    LogisticRegression(max_iter=3000),
    param_grid,
    cv=3,
    scoring='accuracy',
    n_jobs=-1 )

grid.fit(X_train_tfidf, y_train)
print("Best Params:", grid.best_params_)
best_log_reg = grid.best_estimator_
y_val_pred = best_log_reg.predict(X_val_tfidf)
print("Improved Validation Accuracy:", accuracy_score(y_val, y_val_pred))

"""Ø§Ù„Ù†ØªÙŠØ¬Ø©:
- Ø£ÙØ¶Ù„ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª ÙƒØ§Ù†Øª:
  - `C = 5`
  - `penalty = 'l2'`
  - `solver = 'liblinear'`

###  Training Logistic Regression with Best Parameters

Ø¨Ø¹Ø¯ ØªØ­Ø¯ÙŠØ¯ Ø£ÙØ¶Ù„ Ø§Ù„Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ù…Ù† Ø®Ù„Ø§Ù„ GridSearchCVØŒ
Ù‚Ù…Ù†Ø§ Ø¨Ø¥Ø¹Ø§Ø¯Ø© ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ Logistic Regression Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù‡Ø°Ù‡ Ø§Ù„Ù‚ÙŠÙ…:
"""

logreg = LogisticRegression(
    C=5,
    penalty='l2',
    max_iter=300,
    class_weight='balanced',
    solver='liblinear',
)
logreg.fit(X_train_tfidf, y_train)
train_pred = logreg.predict(X_train_tfidf)
val_pred = logreg.predict(X_val_tfidf)
test_pred = logreg.predict(X_test_tfidf)

print("Train Accuracy:", accuracy_score(y_train, train_pred))
print("Validation Accuracy:", accuracy_score(y_val, val_pred))
print("Test Accuracy:", accuracy_score(y_test, test_pred))

print("\n--- Validation Classification Report ---")
print(classification_report(y_val, val_pred))

print("\n--- Test Classification Report ---")
print(classification_report(y_test, test_pred))

"""- Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± Ù…ØªÙ‚Ø§Ø±Ø¨Ø© Ø¬Ø¯Ù‹Ø§ Ù…Ø¹ Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØ­Ù‚Ù‚ØŒ
  Ù…Ù…Ø§ ÙŠØ¤ÙƒØ¯ Ù‚Ø¯Ø±Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¹Ù„Ù‰ Ø§Ù„ØªØ¹Ù…ÙŠÙ….
- Ø§Ù„ÙØ¦Ø§Øª Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ø­Ø§ÙØ¸Øª Ø¹Ù„Ù‰ Ø£Ø¯Ø§Ø¡ Ù…Ø³ØªÙ‚Ø±:
  - Ø§Ù„ÙØ¦Ø§Øª 2ØŒ 3ØŒ 6ØŒ 8ØŒ 10ØŒ 11
- Ø§Ù„ÙØ¦Ø§Øª Ø§Ù„Ù†Ø§Ø¯Ø±Ø© Ù…Ø§ Ø²Ø§Ù„Øª ØªÙ…Ø«Ù„ Ø§Ù„ØªØ­Ø¯ÙŠ Ø§Ù„Ø£ÙƒØ¨Ø±ØŒ
  Ø®Ø§ØµØ© Ù…Ù† Ø­ÙŠØ« Recall ÙˆF1-score.

Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„Ø¹Ø§Ù…Ø©:
- **Test Accuracy â‰ˆ 73.7%**
- **Macro F1 â‰ˆ 0.59**
- **Weighted F1 â‰ˆ 0.73**

Ù‡Ø°Ø§ ÙŠØ¤ÙƒØ¯ Ø£Ù† ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø¥Ø¶Ø§ÙÙŠ
ÙŠØªØ·Ù„Ø¨ Ù†Ù…Ø§Ø°Ø¬ Ø£Ø¹Ù…Ù‚ Ø£Ùˆ ØªÙ…Ø«ÙŠÙ„Ø§Øª Ù„ØºÙˆÙŠØ© Ø£ØºÙ†Ù‰.

###  Linear SVM Baseline

ÙÙŠ Ù‡Ø°Ù‡ Ø§Ù„ØªØ¬Ø±Ø¨Ø© Ø§Ø³ØªØ®Ø¯Ù…Ù†Ø§ Ù†Ù…ÙˆØ°Ø¬ **Linear Support Vector Machine (LinearSVC)**  
Ù…Ø¹ ØªÙ…Ø«ÙŠÙ„ Ø§Ù„Ù†ØµÙˆØµ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… **TF-IDF** ÙˆÙ…Ø¹Ø§Ù„Ø¬Ø© Ø¹Ø¯Ù… ØªÙˆØ§Ø²Ù† Ø§Ù„ÙØ¦Ø§Øª Ø¹Ø¨Ø±:
- `class_weight = 'balanced'`
"""

svm_clf = LinearSVC(C=1.0, class_weight='balanced')
svm_clf.fit(X_train_tfidf, y_train)
train_pred = svm_clf.predict(X_train_tfidf)
val_pred = svm_clf.predict(X_val_tfidf)
test_pred = svm_clf.predict(X_test_tfidf)

print("Train Accuracy:", accuracy_score(y_train, train_pred))
print("Validation Accuracy:", accuracy_score(y_val, val_pred))
print("Test Accuracy:", accuracy_score(y_test, test_pred))

print("\n--- Validation Report ---")
print(classification_report(y_val, val_pred))

print("\n--- Test Report ---")
print(classification_report(y_test, test_pred))

"""Ù†Ù„Ø§Ø­Ø¸:
- Ø¯Ù‚Ø© ØªØ¯Ø±ÙŠØ¨ Ù…Ø±ØªÙØ¹Ø© Ø¬Ø¯Ù‹Ø§ â†’ ØªØ´ÙŠØ± Ø¥Ù„Ù‰ Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù„Ø­ÙØ¸ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨.
- Ø§Ù†Ø®ÙØ§Ø¶ ÙˆØ§Ø¶Ø­ Ø¨ÙŠÙ† Ø§Ù„ØªØ¯Ø±ÙŠØ¨ ÙˆØ§Ù„ØªØ­Ù‚Ù‚/Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± â†’ ÙˆØ¬ÙˆØ¯ **overfitting**
  - ØµØ¹ÙˆØ¨Ø© ÙÙŠ Ø§Ù„ØªÙ…ÙŠÙŠØ² Ø±ØºÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù… `class_weight='balanced'`

###  Linear SVM with Hyperparameter Tuning
"""

param_grid_svm = {
    'C': [0.1, 0.5, 1, 2, 5, 10]}
svm_model = LinearSVC(class_weight='balanced')
grid_svm = GridSearchCV(
    svm_model,
    param_grid_svm,
    cv=3,
    scoring='accuracy',
    n_jobs=-1
)

grid_svm.fit(X_train_tfidf, y_train)
print("Best Params:", grid_svm.best_params_)
best_svm = grid_svm.best_estimator_
val_pred = best_svm.predict(X_val_tfidf)
print("Improved Validation Accuracy:", accuracy_score(y_val, val_pred))

best_svm = grid_svm.best_estimator_

train_pred = best_svm.predict(X_train_tfidf)
val_pred = best_svm.predict(X_val_tfidf)
test_pred = best_svm.predict(X_test_tfidf)

print("Train Accuracy:", accuracy_score(y_train, train_pred))
print("Validation Accuracy:", accuracy_score(y_val, val_pred))
print("Test Accuracy:", accuracy_score(y_test, test_pred))

print("\n--- Validation Classification Report ---")
print(classification_report(y_val, val_pred))

print("\n--- Test Classification Report ---")
print(classification_report(y_test, test_pred))

"""- Ø§Ù†Ø®ÙØ§Ø¶ Ø¯Ù‚Ø© Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ù…Ù‚Ø§Ø±Ù†Ø© Ø¨Ø§Ù„Ù€ baseline â†’ ØªÙ‚Ù„ÙŠÙ„ overfitting
- ØªØ­Ø³Ù† Ø·ÙÙŠÙ Ù„ÙƒÙ† Ù…Ø³ØªÙ‚Ø± ÙÙŠ Ø¯Ù‚Ø© Ø§Ù„ØªØ­Ù‚Ù‚ ÙˆØ§Ù„Ø§Ø®ØªØ¨Ø§Ø±
- ØªÙ‚Ø§Ø±Ø¨ Validation ÙˆTest ÙŠØ¯Ù„ Ø¹Ù„Ù‰ **ØªØ­Ø³Ù† Ø§Ù„ØªØ¹Ù…ÙŠÙ…*

###  Naive Bayes Models Evaluation (TF-IDF Features)

ÙÙŠ Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø±Ø­Ù„Ø© Ù‚Ù…Ù†Ø§ Ø¨ØªØ¬Ø±Ø¨Ø© Ù†Ù…ÙˆØ°Ø¬ÙŠÙ† Ù…Ù† Ø¹Ø§Ø¦Ù„Ø© Naive Bayes:
- Multinomial Naive Bayes (MNB)
- Complement Naive Bayes (CNB)
"""

def evaluate_nb_model(model, X_train, y_train, X_val, y_val, X_test, y_test):
    model.fit(X_train, y_train)
    y_pred_train = model.predict(X_train)
    y_pred_val   = model.predict(X_val)
    y_pred_test  = model.predict(X_test)

    print("===== TRAIN =====")
    print("Accuracy:", accuracy_score(y_train, y_pred_train))
    print(classification_report(y_train, y_pred_train))

    print("===== VALIDATION =====")
    print("Accuracy:", accuracy_score(y_val, y_pred_val))
    print(classification_report(y_val, y_pred_val))

    print("===== TEST =====")
    print("Accuracy:", accuracy_score(y_test, y_pred_test))
    print(classification_report(y_test, y_pred_test))


# Train Multinomial NB
print("\n================ MultinomialNB ================\n")
mnb = MultinomialNB()
evaluate_nb_model(mnb,
                  X_train_tfidf, y_train,
                  X_val_tfidf, y_val,
                  X_test_tfidf, y_test)


# Train Complement NB
print("\n================ ComplementNB ================\n")
cnb = ComplementNB()
evaluate_nb_model(cnb,
                  X_train_tfidf, y_train,
                  X_val_tfidf, y_val,
                  X_test_tfidf, y_test)

"""##  Multinomial Naive Bayes

**Performance Insights**
- Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙŠÙ…ÙŠÙ„ Ø¨Ø´Ø¯Ø© Ø¥Ù„Ù‰ Ø§Ù„ÙØ¦Ø§Øª Ø§Ù„Ø£ÙƒØ«Ø± ØªÙƒØ±Ø§Ø±Ù‹Ø§.
- Ø§Ù„Ø¹Ø¯ÙŠØ¯ Ù…Ù† Ø§Ù„ÙØ¦Ø§Øª (Ù…Ø«Ù„ 7ØŒ 12ØŒ 14ØŒ 15) Ø­ØµÙ„Øª Ø¹Ù„Ù‰:
  - Recall = 0
  - F1-score = 0
- ÙŠØ¸Ù‡Ø± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¶Ø¹ÙÙ‹Ø§ ÙˆØ§Ø¶Ø­Ù‹Ø§ ÙÙŠ Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø¹Ø¯Ù… ØªÙˆØ§Ø²Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª.
- MultinomialNB ØºÙŠØ± Ù…Ù†Ø§Ø³Ø¨ Ù„Ù‡Ø°Ø§ Ø§Ù„ØªØµÙ†ÙŠÙ Ù…ØªØ¹Ø¯Ø¯ Ø§Ù„ÙØ¦Ø§Øª Ù…Ø¹ Ø¹Ø¯Ù… ØªÙˆØ§Ø²Ù† ÙƒØ¨ÙŠØ±.
- Ù„Ø§ ÙŠÙÙ†ØµØ­ Ø¨Ø§Ù„Ø§Ø¹ØªÙ…Ø§Ø¯ Ø¹Ù„ÙŠÙ‡ ÙƒÙ†Ù…ÙˆØ°Ø¬ Ù†Ù‡Ø§Ø¦ÙŠ.
##Complement Naive Bayes

 **Performance Insights**
- ØªØ­Ø³Ù† ÙˆØ§Ø¶Ø­ Ù…Ù‚Ø§Ø±Ù†Ø© Ø¨Ù€ MultinomialNBØŒ Ø®Ø§ØµØ© Ù…Ø¹ Ø§Ù„ÙØ¦Ø§Øª ØºÙŠØ± Ø§Ù„Ù…ØªÙˆØ§Ø²Ù†Ø©.
- Ø§Ù„ÙØ¦Ø§Øª Ø§Ù„ÙƒØ¨ÙŠØ±Ø© (1ØŒ 2ØŒ 3ØŒ 6ØŒ 8ØŒ 10ØŒ 11):
  - Ø­Ù‚Ù‚Øª F1-score Ø¨ÙŠÙ† **0.73 â€“ 0.84**
- Ù…Ø§ Ø²Ø§Ù„Øª Ø§Ù„ÙØ¦Ø§Øª Ø§Ù„Ù†Ø§Ø¯Ø±Ø© ØªØ¹Ø§Ù†ÙŠ Ù…Ù†:
  - Recall Ù…Ù†Ø®ÙØ¶ Ø¬Ø¯Ù‹Ø§
  - Ø¨Ø¹Ø¶ Ø§Ù„ÙØ¦Ø§Øª Ù„Ù… ÙŠØªÙ… Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ù‡Ø§ Ø¥Ø·Ù„Ø§Ù‚Ù‹Ø§.


### Ø§Ù„Ø®Ù„Ø§ØµØ©
- ComplementNB ÙŠØªÙÙˆÙ‚ Ø¨ÙˆØ¶ÙˆØ­ Ø¹Ù„Ù‰ MultinomialNB.
- Ù…Ù†Ø§Ø³Ø¨ ÙƒÙ†Ù…ÙˆØ°Ø¬ baseline Ø³Ø±ÙŠØ¹.
- Ù„ÙƒÙ†Ù‡ Ù„Ø§ ÙŠØµÙ„ Ù„Ø£Ø¯Ø§Ø¡ Logistic Regression Ø£Ùˆ SVM.

###  Complement Naive Bayes with Hyperparameter Tuning
"""

param_grid = {
    'alpha': [0.1, 0.3, 0.5, 1, 2, 3, 5],
    'norm': [True, False]
}

cnb_grid = GridSearchCV(
    ComplementNB(),
    param_grid,
    scoring='accuracy',
    cv=3,
    n_jobs=-1,
    verbose=1
)

cnb_grid.fit(X_train_tfidf, y_train)

print("Best Params:", cnb_grid.best_params_)

best_cnb = cnb_grid.best_estimator_

train_pred = best_cnb.predict(X_train_tfidf)
val_pred   = best_cnb.predict(X_val_tfidf)
test_pred  = best_cnb.predict(X_test_tfidf)

print("\n===== ACCURACY =====")
print("Train:", accuracy_score(y_train, train_pred))
print("Validation:", accuracy_score(y_val, val_pred))
print("Test:", accuracy_score(y_test, test_pred))

print("\n--- Test Classification Report ---")
print(classification_report(y_test, test_pred))

print("\n--- Validation Classification Report ---")
print(classification_report(y_val, val_pred))

"""- ØªØ­Ø³Ù† Ø·ÙÙŠÙ ÙÙŠ Validation Ùˆ Test Ù…Ù‚Ø§Ø±Ù†Ø© Ø¨Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠ.
- Ø§Ù„ÙØ¬ÙˆØ© Ø§Ù„ØµØºÙŠØ±Ø© Ø¨ÙŠÙ† Train Ùˆ Validation ØªØ´ÙŠØ± Ø¥Ù„Ù‰:
  - Ø¹Ø¯Ù… ÙˆØ¬ÙˆØ¯ overfitting Ø­Ø§Ø¯
- Ù…Ø§ Ø²Ø§Ù„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙŠØ¹Ø§Ù†ÙŠ Ù…Ø¹ Ø§Ù„ÙØ¦Ø§Øª Ø§Ù„Ù†Ø§Ø¯Ø±Ø©.

###  Random Forest Classifier with Randomized Search
"""

rf_model = RandomForestClassifier(class_weight='balanced', n_jobs=-1)

param_dist = {
    'n_estimators': [100, 150],
    'max_depth': [10, 20],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4],
    'max_features': ['sqrt'],
}

random_search = RandomizedSearchCV(
    rf_model,
    param_distributions=param_dist,
    n_iter=5,
    cv=2,
    scoring='accuracy',
    n_jobs=-1,
    verbose=1,
    random_state=42
)
random_search.fit(X_train_tfidf, y_train)
print("Best Params:", random_search.best_params_)
best_rf = random_search.best_estimator_

train_pred = best_rf.predict(X_train_tfidf)
val_pred = best_rf.predict(X_val_tfidf)
test_pred = best_rf.predict(X_test_tfidf)

print("\n===== ACCURACY =====")
print("Train Accuracy:", accuracy_score(y_train, train_pred))
print("Validation Accuracy:", accuracy_score(y_val, val_pred))
print("Test Accuracy:", accuracy_score(y_test, test_pred))

print("\n--- Test Classification Report ---")
print(classification_report(y_test, test_pred))

print("\n--- Validation Classification Report ---")
print(classification_report(y_val, val_pred))

"""- Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø¹Ø§Ù… Ù„Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ù†Ø®ÙØ¶ Ù…Ù‚Ø§Ø±Ù†Ø© Ø¨Ù†Ù…Ø§Ø°Ø¬ Ø®Ø·ÙŠØ© Ù…Ø«Ù„:
  - Logistic Regression
  - Linear SVM
- Ø§Ù„ÙØ¬ÙˆØ© Ø§Ù„ØµØºÙŠØ±Ø© Ø¨ÙŠÙ† Train Ùˆ Validation ØªØ´ÙŠØ± Ø¥Ù„Ù‰:
  - Ø¹Ø¯Ù… ÙˆØ¬ÙˆØ¯ overfitting
  - Ù„ÙƒÙ† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙŠØ¹Ø§Ù†ÙŠ Ù…Ù† underfitting
- Random Forest ØºÙŠØ± Ù…Ù†Ø§Ø³Ø¨ Ø¨Ø´ÙƒÙ„ Ø¬ÙŠØ¯ Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù†ØµÙŠØ© Ø¹Ø§Ù„ÙŠØ© Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯ ÙˆÙ…ØªÙ†Ø§Ø«Ø±Ø© Ù…Ø«Ù„ TF-IDF.

## Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ø«Ø§Ù†ÙŠØ©: Embedding + Deep Learning

ØªØ¹ØªÙ…Ø¯ Ù‡Ø°Ù‡ Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© Ø¹Ù„Ù‰ ØªÙ…Ø«ÙŠÙ„ Ø§Ù„Ù†ØµÙˆØµ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Embedding LayerØŒ Ø­ÙŠØ« ÙŠØªÙ… ØªØ­ÙˆÙŠÙ„ ÙƒÙ„ ÙƒÙ„Ù…Ø© Ø¥Ù„Ù‰ Ù…ØªØ¬Ù‡ Ø¹Ø¯Ø¯ÙŠ ÙƒØ«ÙŠÙ ÙŠØ¹ÙƒØ³ Ù…Ø¹Ù†Ø§Ù‡Ø§ ÙˆØ³ÙŠØ§Ù‚Ù‡Ø§. Ø¨Ø¹Ø¯ Ø°Ù„Ùƒ ÙŠØªÙ… ØªÙ…Ø±ÙŠØ± ØªØ³Ù„Ø³Ù„ Ø§Ù„Ù…ØªØ¬Ù‡Ø§Øª Ø¥Ù„Ù‰ Ù†Ù…ÙˆØ°Ø¬ ØªØ¹Ù„Ù… Ø¹Ù…ÙŠÙ‚ Ù…Ø«Ù„ LSTM Ø£Ùˆ BiLSTM Ù„Ø§Ø³ØªØ®Ù„Ø§Øµ Ø§Ù„Ø¹Ù„Ø§Ù‚Ø§Øª Ø§Ù„Ø²Ù…Ù†ÙŠØ© Ø¨ÙŠÙ† Ø§Ù„ÙƒÙ„Ù…Ø§ØªØŒ Ø«Ù… ØªØµÙ†ÙŠÙ Ø§Ù„Ù†Øµ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø·Ø¨Ù‚Ø© Softmax. ØªÙ…ØªØ§Ø² Ù‡Ø°Ù‡ Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© Ø¨Ù‚Ø¯Ø±ØªÙ‡Ø§ Ø¹Ù„Ù‰ ÙÙ‡Ù… ØªØ±ØªÙŠØ¨ Ø§Ù„ÙƒÙ„Ù…Ø§Øª ÙˆØ§Ù„Ø¹Ù„Ø§Ù‚Ø§Øª Ø§Ù„Ø¯Ù„Ø§Ù„ÙŠØ© Ø¨ÙŠÙ†Ù‡Ø§ Ù…Ù‚Ø§Ø±Ù†Ø©Ù‹ Ø¨Ø§Ù„Ø·Ø±Ù‚ Ø§Ù„ØªÙ‚Ù„ÙŠØ¯ÙŠØ© Ù…Ø«Ù„ TF-IDF.

###  ØªØ­Ø¶ÙŠØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù†ØµÙŠØ©

ÙÙŠ Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø±Ø­Ù„Ø© Ù‚Ù…Ù†Ø§ Ø¨Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†ØµÙˆØµ Ù…Ù† Ø¹Ù…ÙˆØ¯ `trimmed_question`
ÙˆØªØ­ÙˆÙŠÙ„Ù‡Ø§ Ø¥Ù„Ù‰ Ù†ÙˆØ¹ `string` Ù„Ø¶Ù…Ø§Ù† Ø§Ù„ØªÙˆØ§ÙÙ‚ Ù…Ø¹ Ø£Ø¯ÙˆØ§Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†ØµÙŠØ©.

Ø¨Ø¹Ø¯ Ø°Ù„Ùƒ ØªÙ… ØªØ­ÙˆÙŠÙ„ Ø§Ù„ÙˆØ³ÙˆÙ… (labels) Ù…Ù† Ù‚ÙŠÙ… Ù†ØµÙŠØ© Ø¥Ù„Ù‰ Ù‚ÙŠÙ… Ø±Ù‚Ù…ÙŠØ© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù…
`LabelEncoder`
"""

X_train_text = train_df['trimmed_question'].astype(str)
X_val_text   = val_df['trimmed_question'].astype(str)
X_test_text  = test_df['trimmed_question'].astype(str)

y_train = train_df['label']
y_val   = val_df['label']
y_test  = test_df['label']

label_encoder = LabelEncoder()
y_train_enc = label_encoder.fit_transform(y_train)
y_val_enc   = label_encoder.transform(y_val)
y_test_enc  = label_encoder.transform(y_test)
num_classes = len(label_encoder.classes_)
print("Number of classes:", num_classes)

"""## Tokenization ÙˆØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†ØµÙˆØµ Ø¥Ù„Ù‰ ØªØ³Ù„Ø³Ù„Ø§Øª Ø±Ù‚Ù…ÙŠØ©
ØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù… `Tokenizer` Ù„ØªØ­ÙˆÙŠÙ„ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø¥Ù„Ù‰ Ø£Ø±Ù‚Ø§Ù…ØŒ Ù…Ø¹ ØªØ­Ø¯ÙŠØ¯:
- `max_words = 50000` Ù„ØªØ­Ø¯ÙŠØ¯ Ø­Ø¬Ù… Ø§Ù„Ù‚Ø§Ù…ÙˆØ³
- Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø±Ù…Ø² `<OOV>` Ù„Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø§Ù„ÙƒÙ„Ù…Ø§Øª ØºÙŠØ± Ø§Ù„Ù…Ø¹Ø±ÙˆÙØ©

Ø¨Ø¹Ø¯ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ ÙÙ‚Ø·ØŒ Ø«Ù… ØªØ­ÙˆÙŠÙ„:
- Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨
- Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ­Ù‚Ù‚
- Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±  
Ø¥Ù„Ù‰ ØªØ³Ù„Ø³Ù„Ø§Øª Ø±Ù‚Ù…ÙŠØ© ØªÙ…Ø«Ù„ ÙƒÙ„ ÙƒÙ„Ù…Ø© Ø¨Ø±Ù‚Ù… ÙØ±ÙŠØ¯.
"""

max_words = 50000
tokenizer = Tokenizer(num_words=max_words, oov_token="<OOV>")
tokenizer.fit_on_texts(X_train_text)

X_train_seq = tokenizer.texts_to_sequences(X_train_text)
X_val_seq   = tokenizer.texts_to_sequences(X_val_text)
X_test_seq  = tokenizer.texts_to_sequences(X_test_text)

"""## Padding ÙˆØªÙˆØ­ÙŠØ¯ Ø£Ø·ÙˆØ§Ù„ Ø§Ù„Ø¬Ù…Ù„

Ù†Ø¸Ø±Ù‹Ø§ Ù„Ø§Ø®ØªÙ„Ø§Ù Ø£Ø·ÙˆØ§Ù„ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ù†ØµÙŠØ©ØŒ Ù‚Ù…Ù†Ø§ Ø¨ØªÙˆØ­ÙŠØ¯ Ø§Ù„Ø·ÙˆÙ„ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù…
`pad_sequences` Ø¨Ø­ÙŠØ« ÙŠØµØ¨Ø­ Ø·ÙˆÙ„ ÙƒÙ„ ØªØ³Ù„Ø³Ù„ `100` ÙƒÙ„Ù…Ø©.

ØªÙ… Ø§Ø¹ØªÙ…Ø§Ø¯:
- `padding='post'` Ù„Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø­Ø´Ùˆ ÙÙŠ Ù†Ù‡Ø§ÙŠØ© Ø§Ù„Ø¬Ù…Ù„Ø©
- Ù‡Ø°Ø§ ÙŠØ³Ù‡Ù„ Ø¹Ù„Ù‰ Ù†Ù…ÙˆØ°Ø¬ LSTM Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¹Ù„Ù‰ Ø¯ÙØ¹Ø§Øª Ø«Ø§Ø¨ØªØ© Ø§Ù„Ø´ÙƒÙ„
"""

max_len = 80
X_train_pad = pad_sequences(
    X_train_seq,
    maxlen=max_len,
    padding='post',
    truncating='post'
)

X_val_pad = pad_sequences(
    X_val_seq,
    maxlen=max_len,
    padding='post',
    truncating='post'
)

X_test_pad = pad_sequences(
    X_test_seq,
    maxlen=max_len,
    padding='post',
    truncating='post'
)

"""##Ø¨Ù†Ø§Ø¡ Ù†Ù…ÙˆØ°Ø¬ LSTM

"""

lengths = [len(seq) for seq in X_train_seq]
np.percentile(lengths, [50, 75, 90, 95, 99])
max_len = 80

num_classes = df['label'].nunique()
embedding_dim = 128

model_lstm = Sequential([
    Embedding(
        input_dim=max_words,
        output_dim=embedding_dim,
        input_length=max_len
    ),

    LSTM(128, return_sequences=False),
    Dropout(0.5),
    Dense(64, activation='relu'),
    Dropout(0.3),
    Dense(num_classes, activation='softmax')
])

model_lstm.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

"""### Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¹Ø¯Ù… ØªÙˆØ§Ø²Ù† Ø§Ù„ÙØ¦Ø§Øª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Class Weights

"""

classes = np.unique(y_train)

class_weights = compute_class_weight(
    class_weight='balanced',
    classes=classes,
    y=y_train
)

class_weights_dict = dict(zip(classes, class_weights))

history_lstm = model_lstm.fit(
    X_train_pad,
    y_train,
    validation_data=(X_val_pad, y_val),
    epochs=10,
    batch_size=64,
    class_weight=class_weights_dict
)

"""Ù†Ù„Ø§Ø­Ø¸ ØªØ­Ø³Ù†Ø§ ØªØ¯Ø±ÙŠØ¬ÙŠØ§ ÙÙŠ Training Accuracy Ù…Ù† Ù‚ÙŠÙ… Ù…Ù†Ø®ÙØ¶Ø© Ø¬Ø¯Ø§ ÙÙŠ Ø§Ù„Ø¨Ø¯Ø§ÙŠØ© Ø¥Ù„Ù‰ Ø£ÙƒØ«Ø± Ù…Ù† 91% ÙÙŠ Ù†Ù‡Ø§ÙŠØ© Ø§Ù„ØªØ¯Ø±ÙŠØ¨.

Validation Accuracy Ø§Ø±ØªÙØ¹Øª ØªØ¯Ø±ÙŠØ¬ÙŠØ§ Ø£ÙŠØ¶Ø§ØŒ Ø­ÙŠØ« ÙˆØµÙ„Øª Ø¥Ù„Ù‰ Ø­ÙˆØ§Ù„ÙŠ 60%.

Ø¨Ø¹Ø¯ Ø¹Ø¯Ø© Ø¹ØµÙˆØ±ØŒ Ø¨Ø¯Ø£ Validation Loss Ø¨Ø§Ù„Ø§Ø²Ø¯ÙŠØ§Ø¯ Ø±ØºÙ… ØªØ­Ø³Ù† Ø¯Ù‚Ø© Ø§Ù„ØªØ¯Ø±ÙŠØ¨ØŒ Ù…Ù…Ø§ ÙŠØ´ÙŠØ± Ø¥Ù„Ù‰ Ø¨Ø¯Ø§ÙŠØ© Ø­Ø¯ÙˆØ« Overfitting.
"""

test_loss, test_acc = model_lstm.evaluate(X_test_pad, y_test)
print("Test Accuracy:", test_acc)

print("\n--- Test Classification Report ---")
print(classification_report(y_test, test_pred))

"""# Ø¨Ù†Ø§Ø¡ Ù†Ù…ÙˆØ°Ø¬ BiLSTM

ÙÙŠ Ù‡Ø§Ù„Ø®Ù„ÙŠØ© Ø¹Ù… Ù†Ø¨Ù†ÙŠ Ù†Ù…ÙˆØ°Ø¬ BiLSTM Ù„ØªØµÙ†ÙŠÙ Ø§Ù„Ù†ØµÙˆØµ.

Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨ÙŠØ³ØªØ®Ø¯Ù… Embedding Layer Ù„ØªÙ…Ø«ÙŠÙ„ Ø§Ù„ÙƒÙ„Ù…Ø§ØªØŒ ÙŠÙ„ÙŠ Ø¨Ø¹Ø¯Ù‡Ø§ ÙŠÙ…Ø±Ø±Ù‡Ø§ Bidirectional LSTM Ù„Ø§Ø³ØªØ®Ù„Ø§Øµ Ø§Ù„Ø¹Ù„Ø§Ù‚Ø§Øª Ø§Ù„Ø²Ù…Ù†ÙŠØ© Ø¨ÙŠÙ† Ø§Ù„ÙƒÙ„Ù…Ø§ØªØŒ ÙˆÙ…Ù† Ø«Ù… Ø·Ø¨Ù‚Ø§Øª Dense ÙˆDropout Ù„ØªÙ‚Ù„ÙŠÙ„ Ø§Ù„Ø¥ÙØ±Ø§Ø· ÙÙŠ Ø§Ù„ØªØ¹Ù„Ù… ÙˆØªØµÙ†ÙŠÙ Ø§Ù„Ù†ØµÙˆØµ.
"""

model_bilstm = Sequential([
    Embedding(
        input_dim=max_words,
        output_dim=embedding_dim,
        input_length=max_len
    ),

    Bidirectional(LSTM(128)),
    Dropout(0.5),
    Dense(64, activation='relu'),
    Dropout(0.3),
    Dense(num_classes, activation='softmax')
])

model_bilstm.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

"""ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ BiLSTM"""

history_bilstm = model_bilstm.fit(
    X_train_pad,
    y_train,
    validation_data=(X_val_pad, y_val),
    epochs=10,
    batch_size=64,
    class_weight=class_weights_dict
)

"""Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ø¯Ø£ Ø¨Ø¯Ù‚Ø© Ù…Ù†Ø®ÙØ¶Ø© Ø¬Ø¯Ø§ ÙÙŠ Ø§Ù„Ø¨Ø¯Ø§ÙŠØ© (â‰ˆ18%) Ø¹Ù„Ù‰ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ ÙˆØ¯Ù‚Ø© Ù…Ù†Ø®ÙØ¶Ø© Ø¹Ù„Ù‰ Ø§Ù„ØªØ­Ù‚Ù‚ (â‰ˆ39%).

Ù…Ø¹ ØªÙ‚Ø¯Ù… Ø§Ù„ØªØ¯Ø±ÙŠØ¨ØŒ ÙŠØªØ­Ø³Ù† Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø¹Ù„Ù‰ ÙƒÙ„ Ù…Ù† Ø§Ù„ØªØ¯Ø±ÙŠØ¨ ÙˆØ§Ù„ØªØ­Ù‚Ù‚ØŒ Ù…Ù…Ø§ ÙŠØ¯Ù„ Ø¹Ù„Ù‰ Ø£Ù† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙŠØªØ¹Ù„Ù… Ø§Ù„ØªÙ…Ø«ÙŠÙ„ Ø§Ù„Ù…Ù†Ø§Ø³Ø¨ Ù„Ù„Ù†ØµÙˆØµ.

Ø¹Ù„Ù‰ Ø§Ù„Ø±ØºÙ… Ù…Ù† ØªØ­Ø³Ù† Ø§Ù„Ø¯Ù‚Ø© Ø§Ù„ØªØ¯Ø±ÙŠØ¨ÙŠØ© Ø¨Ø´ÙƒÙ„ ÙƒØ¨ÙŠØ± (>96%)ØŒ Ø¯Ù‚Ø© Ø§Ù„ØªØ­Ù‚Ù‚ ØªØµÙ„ Ø¥Ù„Ù‰ Ø­ÙˆØ§Ù„ÙŠ 64%ØŒ Ù…Ù…Ø§ ÙŠØ´ÙŠØ± Ø¥Ù„Ù‰ Ø¨Ø¹Ø¶ Ø§Ù„Ø¥ÙØ±Ø§Ø· ÙÙŠ Ø§Ù„ØªØ¹Ù„Ù‘Ù… (overfitting).
"""

test_loss, test_acc = model_bilstm.evaluate(X_test_pad, y_test)
print("BiLSTM Test Accuracy:", test_acc)

print("\n--- Test Classification Report ---")
print(classification_report(y_test, test_pred))

"""Ø¯Ù‚Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¹Ù„Ù‰ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø­ÙˆØ§Ù„ÙŠ 64.5%ØŒ ÙˆÙ‡Ùˆ Ù‚Ø±ÙŠØ¨ Ù…Ù† Ø¯Ù‚Ø© Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù…Ø§ ÙŠØ¯Ù„ Ø¹Ù„Ù‰ Ø«Ø¨Ø§Øª Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬.

Ù‚ÙŠÙ…Ø© Ø§Ù„Ø®Ø³Ø§Ø±Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± Ù…Ø±ØªÙØ¹Ø© Ù†Ø³Ø¨ÙŠÙ‹Ø§ (â‰ˆ2.17)ØŒ Ù…Ù…Ø§ ÙŠØ´ÙŠØ± Ø¥Ù„Ù‰ Ø£Ù† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙŠÙˆØ§Ø¬Ù‡ ØµØ¹ÙˆØ¨Ø© ÙÙŠ Ø¨Ø¹Ø¶ Ø§Ù„Ø¹ÙŠÙ†Ø§Øª

# Ø¨Ù†Ø§Ø¡ Ù†Ù…ÙˆØ°Ø¬ BiLSTM Ù…Ø­Ø³Ù‘Ù† (BiLSTM Regularized)

Ù‡Ø§Ù„Ø®Ù„ÙŠØ© Ø¹Ù… Ù†Ø¨Ù†ÙŠ Ù†Ø³Ø®Ø© Ù…Ø­Ø³Ù‘Ù†Ø© Ù…Ù† Ù†Ù…ÙˆØ°Ø¬ BiLSTM Ù„ØªÙ‚Ù„ÙŠÙ„ Ø§Ù„Ø¥ÙØ±Ø§Ø· ÙÙŠ Ø§Ù„ØªØ¹Ù„Ù…. Ø§Ù„ØªØ¹Ø¯ÙŠÙ„Ø§Øª ØªØ´Ù…Ù„:

Ø²ÙŠØ§Ø¯Ø© Ø£Ø¨Ø¹Ø§Ø¯ Ø§Ù„Ù€ Embedding Ø¥Ù„Ù‰ 300

Ø¥Ø¶Ø§ÙØ© Dropout Ø¥Ø¶Ø§ÙÙŠØ© Ù‚Ø¨Ù„ ÙˆØ¨Ø¹Ø¯ Ø§Ù„Ù€ LSTM ÙˆDense layer Ù„Ù…Ù‚Ø§ÙˆÙ…Ø© Ø§Ù„Ø¥ÙØ±Ø§Ø· ÙÙŠ Ø§Ù„ØªØ¹Ù„Ù….

Ø·Ø¨Ù‚Ø© Dense Ø£ÙƒØ¨Ø± (128 ÙˆØ­Ø¯Ø©) Ù„ØªÙ‚ÙˆÙŠØ© Ù‚Ø¯Ø±Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¹Ù„Ù‰ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…ÙŠØ²Ø§Øª.
"""

model_bilstm_reg = Sequential([
    Embedding(
        input_dim=max_words,
        output_dim=300,
        input_length=max_len
    ),

    Dropout(0.3),
    Bidirectional(LSTM(128, return_sequences=False)),
    Dropout(0.4),
    Dense(128, activation='relu'),
    Dropout(0.4),
    Dense(num_classes, activation='softmax')
])

model_bilstm_reg.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

"""## Ø¥Ø¹Ø¯Ø§Ø¯ Early Stopping

Ù‡Ù†Ø§ Ù†Ø¶ÙŠÙ EarlyStopping Ù„Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„ØªØ¯Ø±ÙŠØ¨ ØªÙ„Ù‚Ø§Ø¦ÙŠØ§ Ø¥Ø°Ø§ Ù„Ù… ÙŠØªØ­Ø³Ù† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ­Ù‚Ù‚ Ù„Ù…Ø¯Ø© Ù…Ø¹ÙŠÙ†Ø©(3 epochs)ØŒ ÙˆØ§Ø³ØªØ¹Ø§Ø¯Ø© Ø£ÙØ¶Ù„ Ø§Ù„Ø£ÙˆØ²Ø§Ù† Ù„ØªÙ‚Ù„ÙŠÙ„ Ø§Ù„Ø¥ÙØ±Ø§Ø· ÙÙŠ Ø§Ù„ØªØ¹Ù„Ù….
"""

early_stopping = EarlyStopping(
    monitor='val_loss',
    patience=3,
    restore_best_weights=True)

history_bilstm_reg = model_bilstm_reg.fit(
    X_train_pad, y_train,
    validation_data=(X_val_pad, y_val),
    epochs=20,
    batch_size=64,
    callbacks=[early_stopping])

"""Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ø¯Ø£ Ø¨Ø¯Ù‚Ø© Ù…Ù†Ø®ÙØ¶Ø© Ø¹Ù„Ù‰ Ø§Ù„Ù€ training (33%) ÙˆÙ„ÙƒÙ†Ù‡ ØªØ­Ø³Ù† Ø¨Ø³Ø±Ø¹Ø© Ø®Ù„Ø§Ù„ Ø§Ù„Ù€ epochs Ø§Ù„Ø£ÙˆÙ„Ù‰.

Ø¯Ù‚Ø© Ø§Ù„ØªØ­Ù‚Ù‚ (val_accuracy) ÙˆØµÙ„Øª Ø¥Ù„Ù‰ Ø­ÙˆØ§Ù„ÙŠ 69-70% ÙÙŠ Ø£ÙˆÙ„ 3 epochsØŒ ÙˆÙ‡Ø°Ø§ ÙŠØ¯Ù„ Ø¹Ù„Ù‰ Ø£Ù† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ØªØ¹Ù„Ù… ØªÙ…Ø«ÙŠÙ„Ø§Øª Ù‚ÙˆÙŠØ© Ø¨Ø³Ø±Ø¹Ø©.

Ø¨Ø¹Ø¯ Ø§Ù„Ù€ epoch Ø§Ù„Ø«Ø§Ù„Ø«ØŒ Ø§Ù„Ø¯Ù‚Ø© Ø¹Ù„Ù‰ Ø§Ù„ØªØ­Ù‚Ù‚ Ù„Ù… ØªØªØ­Ø³Ù†ØŒ Ù…Ù…Ø§ Ø£Ø¯Ù‰ Ø¥Ù„Ù‰ ØªÙˆÙ‚Ù Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ù…Ø¨ÙƒØ±Ù‹Ø§ Ø¨ÙˆØ§Ø³Ø·Ø© EarlyStopping.

Ù‡Ø°Ø§ ÙŠÙˆØ¶Ø­ Ø£Ù† Ø§Ù„Ù€ BiLSTM Ø§Ù„Ù…Ø­Ø³Ù‘Ù† Ù…Ø¹ Dropout ÙˆEmbedding Ø£ÙƒØ¨Ø± Ù‚Ø§Ø¯Ø± Ø¹Ù„Ù‰ ØªØ¹Ù„Ù… Ù…ÙŠØ²Ø§Øª Ø¬ÙŠØ¯Ø© Ø¨Ø³Ø±Ø¹Ø© Ù…Ø¹ Ù…Ù‚Ø§ÙˆÙ…Ø© Ø§Ù„Ø¥ÙØ±Ø§Ø· ÙÙŠ Ø§Ù„ØªØ¹Ù„Ù….
"""

test_loss, test_acc = model_bilstm_reg.evaluate(X_test_pad, y_test)
print("Improved BiLSTM Test Accuracy:", test_acc)

"""- Ø¯Ù‚Ø© Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø¨Ù„ØºØª Ø­ÙˆØ§Ù„ÙŠ 69.6% ÙˆÙ‡ÙŠ Ø£ÙØ¶Ù„ Ù…Ù† Ù†Ù…Ø§Ø°Ø¬ LSTM ÙˆBiLSTM Ø§Ù„Ø³Ø§Ø¨Ù‚Ø© Ø¨Ø¯ÙˆÙ† ØªØ­Ø³ÙŠÙ†Ø§Øª.

- Ù‡Ø°Ø§ ÙŠØ´ÙŠØ± Ø¥Ù„Ù‰ Ø£Ù† Ø§Ù„ØªØ¹Ø¯ÙŠÙ„Ø§Øª (Ø²ÙŠØ§Ø¯Ø© Ø­Ø¬Ù… Ø§Ù„Ù€ EmbeddingØŒ Dropout Ø¥Ø¶Ø§ÙÙŠØ©ØŒ Dense Ø£ÙƒØ¨Ø±ØŒ ÙˆØ§Ø³ØªØ®Ø¯Ø§Ù… EarlyStopping) Ø³Ø§Ø¹Ø¯Øª Ø¹Ù„Ù‰ ØªØ­Ø³ÙŠÙ† Ù‚Ø¯Ø±Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¹Ù„Ù‰ Ø§Ù„ØªØ¹Ù…ÙŠÙ… ÙˆØªÙ‚Ù„ÙŠÙ„ Ø§Ù„Ø¥ÙØ±Ø§Ø· ÙÙŠ Ø§Ù„ØªØ¹Ù„Ù….

- Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù…ØªÙˆØ§Ø²Ù† Ø¨ÙŠÙ† Ø§Ù„ØªØ¯Ø±ÙŠØ¨ ÙˆØ§Ù„ØªØ­Ù‚Ù‚ ÙŠØ´ÙŠØ± Ø¥Ù„Ù‰ Ø£Ù† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ØªØ¹Ù„Ù… ØªÙ…Ø«ÙŠÙ„Ø§Øª Ø¬ÙŠØ¯Ø© Ù„Ù„Ù†ØµÙˆØµ ÙˆÙ„Ù… ÙŠØ¨Ø§Ù„Øº ÙÙŠ Ø­ÙØ¸ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ ÙÙ‚Ø·.
"""

test_pred_prob = model_bilstm_reg.predict(X_test_pad)
test_pred = np.argmax(test_pred_prob, axis=1)
print("\nClassification Report on Test Set:")
print(classification_report(y_test, test_pred))

"""## ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ BiLSTM Ù…Ø¹ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø£ÙˆØ²Ø§Ù† Ø§Ù„ÙØ¦Ø§Øª (Class Weights)"""

history_bilstm = model_bilstm.fit(
    X_train_pad,
    y_train,
    validation_data=(X_val_pad, y_val),
    epochs=20,
    batch_size=64,
    class_weight=class_weights_dict,
    callbacks=[early_stopping]
)

"""- Ù†Ù„Ø§Ø­Ø¸ Ø£Ù† Ø¯Ù‚Ø© Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ù…Ø±ØªÙØ¹Ø© Ø¬Ø¯Ù‹Ø§ Ù…Ù†Ø° Ø§Ù„Ø¨Ø¯Ø§ÙŠØ© (â‰ˆ97%)ØŒ Ù…Ø§ ÙŠØ¯Ù„ Ø¹Ù„Ù‰ Ø£Ù† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù‚Ø§Ø¯Ø± Ø¹Ù„Ù‰ Ø­ÙØ¸ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø¨Ø³Ø±Ø¹Ø©.

- Ø¨Ø§Ù„Ù…Ù‚Ø§Ø¨Ù„ØŒ Ø¯Ù‚Ø© Ø§Ù„ØªØ­Ù‚Ù‚ (val_accuracy) Ø¨Ù‚ÙŠØª Ø¨Ø­Ø¯ÙˆØ¯ 64â€“65% ÙˆÙ„Ù… ØªØªØ­Ø³Ù† Ø¨Ø´ÙƒÙ„ ÙˆØ§Ø¶Ø­.

- Ø§Ø±ØªÙØ§Ø¹ val_loss Ù…Ø¹ ÙƒÙ„ epoch ÙŠØ´ÙŠØ± Ø¥Ù„Ù‰ overfitting ÙˆØ§Ø¶Ø­ Ø±ØºÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù… class weights ÙˆEarlyStopping.

"""

test_loss, test_acc = model_bilstm.evaluate(X_test_pad, y_test)
print("Improved BiLSTM with class-weight Test Accuracy:", test_acc)

print("\n--- Test Classification Report ---")
print(classification_report(y_test, test_pred))

"""Ø¯Ù‚Ø© Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø¨Ù„ØºØª Ø­ÙˆØ§Ù„ÙŠ 64.4%ØŒ ÙˆÙ‡ÙŠ Ø£Ù‚Ù„ Ù…Ù† Ø¯Ù‚Ø© Ù†Ù…ÙˆØ°Ø¬ BiLSTM Ø§Ù„Ù…Ø­Ø³Ù‘Ù† Ù…Ø¹ EarlyStopping.

Ù‡Ø°Ø§ ÙŠØ¤ÙƒØ¯ Ø£Ù†:

Ø§Ø³ØªØ®Ø¯Ø§Ù… class_weight Ø¨Ø¯ÙˆÙ† ØªÙ†Ø¸ÙŠÙ… Ø¥Ø¶Ø§ÙÙŠ Ù‚ÙˆÙŠ Ù‚Ø¯ ÙŠØ¤Ø¯ÙŠ Ø¥Ù„Ù‰ overfitting.

Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø­Ø³Ù‘Ù† Ø§Ù„Ø³Ø§Ø¨Ù‚ (Embedding Ø£ÙƒØ¨Ø± + Dropout Ø£Ù‚ÙˆÙ‰ + EarlyStopping) ÙƒØ§Ù† Ø£ÙƒØ«Ø± Ø§Ø³ØªÙ‚Ø±Ø§Ø±Ù‹Ø§ ÙˆØ£ÙØ¶Ù„ ÙÙŠ Ø§Ù„ØªØ¹Ù…ÙŠÙ….

# CNN

ÙÙŠ Ù‡Ø°Ù‡ Ø§Ù„Ø®Ù„ÙŠØ© Ù†Ù‚ÙˆÙ… Ø¨Ø¨Ù†Ø§Ø¡ Ù†Ù…ÙˆØ°Ø¬ Convolutional Neural Network (CNN) Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†ØµÙˆØµ.
ØªØ¹ØªÙ…Ø¯ Ø§Ù„ÙÙƒØ±Ø© Ø¹Ù„Ù‰ Ø§Ø³ØªØ®Ø¯Ø§Ù… Embedding Layer Ù„ØªØ­ÙˆÙŠÙ„ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø¥Ù„Ù‰ Ù…ØªØ¬Ù‡Ø§Øª Ø¹Ø¯Ø¯ÙŠØ©ØŒ Ø«Ù… ØªØ·Ø¨ÙŠÙ‚ Conv1D Ù„Ø§Ø³ØªØ®Ù„Ø§Øµ Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ù…Ø­Ù„ÙŠØ© (n-grams) Ø¯Ø§Ø®Ù„ Ø§Ù„Ø¬Ù…Ù„ØŒ Ù…Ø«Ù„ Ø§Ù„Ø¹Ø¨Ø§Ø±Ø§Øª Ø£Ùˆ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ØªØ¬Ø§ÙˆØ±Ø© Ø§Ù„Ù…Ù‡Ù…Ø© Ù„Ù„ØªØµÙ†ÙŠÙ.
Ø¨Ø¹Ø¯ Ø°Ù„Ùƒ Ù†Ø³ØªØ®Ø¯Ù… Global Max Pooling Ù„Ø§Ø®ØªÙŠØ§Ø± Ø£Ù‡Ù… Ø§Ù„Ø®ØµØ§Ø¦Øµ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬Ø©ØŒ Ø«Ù… Ø·Ø¨Ù‚Ø§Øª Fully Connected Ù„Ø¥Ø¬Ø±Ø§Ø¡ Ø§Ù„ØªØµÙ†ÙŠÙ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ.
"""

MAX_WORDS = 50000
model_cnn = Sequential([
    Embedding(
        input_dim=MAX_WORDS,
        output_dim=128,
        input_length=max_len
    ),

    Conv1D(filters=128, kernel_size=5, activation='relu'),
    GlobalMaxPooling1D(),
    Dense(128, activation='relu'),
    Dropout(0.5),
    Dense(num_classes, activation='softmax')
])

model_cnn.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

history_cnn = model_cnn.fit(
    X_train_pad, y_train,
    validation_data=(X_val_pad, y_val),
    epochs=20,
    batch_size=32,
    callbacks=[early_stopping],
    verbose=1
)

"""Ù†Ù„Ø§Ø­Ø¸ Ø§Ø±ØªÙØ§Ø¹Ù‹Ø§ Ø³Ø±ÙŠØ¹Ù‹Ø§ ÙÙŠ Ø¯Ù‚Ø© Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø­ØªÙ‰ ÙˆØµÙ„Øª Ø¥Ù„Ù‰ Ø£ÙƒØ«Ø± Ù…Ù† 97%.

Ø¯Ù‚Ø© Ø§Ù„ØªØ­Ù‚Ù‚ ÙˆØµÙ„Øª Ø¥Ù„Ù‰ Ø­ÙˆØ§Ù„ÙŠ 71.7% Ø«Ù… Ø¨Ø¯Ø£Øª Ø¨Ø§Ù„Ø§Ù†Ø®ÙØ§Ø¶.

Ù‡Ø°Ø§ Ø§Ù„Ø³Ù„ÙˆÙƒ ÙŠØ¯Ù„ Ø¹Ù„Ù‰ Ø£Ù† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬:

ØªØ¹Ù„Ù‘Ù… Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø¨Ø³Ø±Ø¹Ø©.

Ù„ÙƒÙ†Ù‡ Ø¨Ø¯Ø£ ÙŠØ¹Ø§Ù†ÙŠ Ù…Ù† overfitting Ø¨Ø¹Ø¯ Ø¹Ø¯Ø© epochs.
"""

test_loss, test_acc = model_cnn.evaluate(X_test_pad, y_test, verbose=1)
print("CNN Test Accuracy:", test_acc)
y_pred_probs = model_cnn.predict(X_test_pad)
y_pred = np.argmax(y_pred_probs, axis=1)
print(classification_report(y_test, y_pred))

"""Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø¹Ø§Ù… Ø£ÙØ¶Ù„ Ù…Ù†:

LSTM

BiLSTM Ø§Ù„ØªÙ‚Ù„ÙŠØ¯ÙŠ

ÙˆÙ‚Ø±ÙŠØ¨ Ø¬Ø¯Ù‹Ø§ Ù…Ù† Ø£ÙØ¶Ù„ Ù†Ù…ÙˆØ°Ø¬ BiLSTM Ù…Ø­Ø³Ù‘Ù†.

ØªØ­Ù„ÙŠÙ„ ØªÙ‚Ø±ÙŠØ± Ø§Ù„ØªØµÙ†ÙŠÙ:

- Ø§Ù„ÙØ¦Ø§Øª Ø§Ù„ÙƒØ¨ÙŠØ±Ø© (Ù…Ø«Ù„ 1ØŒ 2ØŒ 10ØŒ 11) Ø­Ù‚Ù‚Øª Ø£Ø¯Ø§Ø¡Ù‹ Ø¬ÙŠØ¯Ù‹Ø§ Ù…Ù† Ø­ÙŠØ« precision Ùˆrecall.

- Ø¨Ø¹Ø¶ Ø§Ù„ÙØ¦Ø§Øª Ø§Ù„Ù†Ø§Ø¯Ø±Ø© (Ù…Ø«Ù„ 7ØŒ 12ØŒ 14ØŒ 15) Ù„Ù… ÙŠØªÙ… Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ù‡Ø§ ØªÙ‚Ø±ÙŠØ¨Ù‹Ø§:

Ù…Ù…Ø§ Ø£Ø¯Ù‰ Ø¥Ù„Ù‰ Ù‚ÙŠÙ… precision = 0.

## Ø¨Ù†Ø§Ø¡ Ù†Ù…ÙˆØ°Ø¬ CNN Ù…Ø¹ Class Weights

ÙÙŠ Ù‡Ø°Ù‡ Ø§Ù„Ø®Ù„ÙŠØ© Ù†Ù‚ÙˆÙ… Ø¨Ø¨Ù†Ø§Ø¡ Ù†Ù…ÙˆØ°Ø¬ CNN
 Ù…Ø´Ø§Ø¨Ù‡ Ù„Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø³Ø§Ø¨Ù‚ØŒ ÙˆÙ„ÙƒÙ† Ø§Ù„Ù‡Ø¯Ù Ù‡Ù†Ø§ Ù‡Ùˆ ØªØ­Ø³ÙŠÙ† Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¹Ù„Ù‰ Ø§Ù„ÙØ¦Ø§Øª ØºÙŠØ± Ø§Ù„Ù…ØªÙˆØ§Ø²Ù†Ø© Ù„Ø§Ø­Ù‚Ù‹Ø§ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… class weights Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªØ¯Ø±ÙŠØ¨.
"""

model_cnn_cw = Sequential([
    Embedding(input_dim=MAX_WORDS, output_dim=128, input_length=max_len),
    Conv1D(128, 5, activation='relu'),
    GlobalMaxPooling1D(),
    Dense(128, activation='relu'),
    Dropout(0.5),
    Dense(num_classes, activation='softmax')
])
model_cnn_cw.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

history_cnn_cw = model_cnn_cw.fit(
    X_train_pad, y_train,
    validation_data=(X_val_pad, y_val),
    epochs=20,
    batch_size=64,
    class_weight=class_weights_dict,
    callbacks=[early_stopping]
)

"""Ø¯Ù‚Ø© Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ø±ØªÙØ¹Øª Ø¨Ø³Ø±Ø¹Ø© ÙˆÙˆØµÙ„Øª Ø¥Ù„Ù‰ Ø£ÙƒØ«Ø± Ù…Ù† 97%.

Ø¯Ù‚Ø© Ø§Ù„ØªØ­Ù‚Ù‚ Ø§Ø³ØªÙ‚Ø±Øª Ø­ÙˆÙ„ 68%.

Ø§Ù„ÙØ¬ÙˆØ© Ø¨ÙŠÙ† Ø¯Ù‚Ø© Ø§Ù„ØªØ¯Ø±ÙŠØ¨ ÙˆØ§Ù„ØªØ­Ù‚Ù‚ ØªØ´ÙŠØ± Ø¥Ù„Ù‰ ÙˆØ¬ÙˆØ¯ overfittingØŒ Ù„ÙƒÙ† Ø£Ù‚Ù„ Ø­Ø¯Ù‘Ø© Ø¹Ù„Ù‰ Ø§Ù„ÙØ¦Ø§Øª Ø§Ù„Ù†Ø§Ø¯Ø±Ø© Ù…Ù‚Ø§Ø±Ù†Ø© Ø¨Ù†Ù…ÙˆØ°Ø¬ CNN Ø¨Ø¯ÙˆÙ† class weights.
"""

test_loss, test_acc = model_cnn_cw.evaluate(X_test_pad, y_test)
print("CNN + Class Weights Test Accuracy:", test_acc)
y_pred = np.argmax(model_cnn_cw.predict(X_test_pad), axis=1)

print(classification_report(y_test, y_pred, digits=2))

"""Test Accuracy â‰ˆ 66.8%

Ø£Ù‚Ù„ Ù…Ù† CNN Ø¨Ø¯ÙˆÙ† class weights (~70%)

ÙˆØ£Ù‚Ù„ Ù…Ù† BiLSTM Ø§Ù„Ù…Ø­Ø³Ù‘Ù† (~69.6%)

 **ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙØ¦Ø§Øª Ø§Ù„Ù†Ø§Ø¯Ø±Ø©:**

Ù…Ù‚Ø§Ø±Ù†Ø©Ù‹ Ø¨Ù€ CNN Ø¨Ø¯ÙˆÙ† class weights:

ØªØ­Ø³Ù† ÙˆØ§Ø¶Ø­ ÙÙŠ recall Ù„Ù„ÙØ¦Ø§Øª Ø§Ù„ØµØºÙŠØ±Ø© Ù…Ø«Ù„:

Ø§Ù„ÙØ¦Ø© 7
, Ø§Ù„ÙØ¦Ø© 12
 , Ø§Ù„ÙØ¦Ø© 14
 , Ø§Ù„ÙØ¦Ø© 15

Ù„Ù… ØªØ¹Ø¯ Ø¨Ø¹Ø¶ Ø§Ù„ÙØ¦Ø§Øª Ù…Ù‡Ù…Ù„Ø© Ø¨Ø§Ù„ÙƒØ§Ù…Ù„ (recall = 0)ØŒ ÙˆÙ‡Ùˆ ØªØ­Ø³Ù† Ù…Ù‡Ù….

 **Ø§Ù„Ù…Ù‚Ø§ÙŠØ¶Ø© (Trade-off):**

ØªØ­Ø³Ù† Ø£Ø¯Ø§Ø¡ Ø§Ù„ÙØ¦Ø§Øª Ø§Ù„Ù†Ø§Ø¯Ø±Ø© -

Ø§Ù†Ø®ÙØ§Ø¶ Ø§Ù„Ø¯Ù‚Ø© Ø§Ù„Ø¹Ø§Ù…Ø© Ù„Ù„Ù†Ù…ÙˆØ°Ø¬ -

##  Multi- Kernel CNN
"""

MAX_LEN = 100
MAX_WORDS= 50000
X_train_pad = pad_sequences(X_train_seq, maxlen=MAX_LEN, padding='post', truncating='post')
X_val_pad   = pad_sequences(X_val_seq,   maxlen=MAX_LEN, padding='post', truncating='post')
X_test_pad  = pad_sequences(X_test_seq,  maxlen=MAX_LEN, padding='post', truncating='post')

inputs = Input(shape=(MAX_LEN,))

x = Embedding(
    input_dim=MAX_WORDS,
    output_dim=128,
    input_length=MAX_LEN
)(inputs)

x = SpatialDropout1D(0.3)(x)

conv_3 = Conv1D(128, 3, activation='relu')(x)
conv_4 = Conv1D(128, 4, activation='relu')(x)
conv_5 = Conv1D(128, 5, activation='relu')(x)

pool_3 = GlobalMaxPooling1D()(conv_3)
pool_4 = GlobalMaxPooling1D()(conv_4)
pool_5 = GlobalMaxPooling1D()(conv_5)

x = Concatenate()([pool_3, pool_4, pool_5])

x = BatchNormalization()(x)
x = Dense(256, activation='relu')(x)
x = Dropout(0.5)(x)

outputs = Dense(num_classes, activation='softmax')(x)

model_cnn_adv = Model(inputs, outputs)

model_cnn_adv.compile(
    optimizer='adam',
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

print("Tokenizer vocab size:", len(tokenizer.word_index))

print("Max value in X_train_pad:", np.max(X_train_pad))
print("Max value in X_val_pad:", np.max(X_val_pad))
print("Max value in X_test_pad:", np.max(X_test_pad))

vocab_size = 50000

X_train_pad = np.clip(X_train_pad, 0, vocab_size - 1)
X_val_pad = np.clip(X_val_pad, 0, vocab_size - 1)
X_test_pad = np.clip(X_test_pad, 0, vocab_size - 1)

print(f"ØªÙ… ØªÙ‚Ù„ÙŠÙ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª. Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ø¢Ù† Ø¨ÙŠÙ† 0 Ùˆ{vocab_size-1}")

history_cnn_adv = model_cnn_adv.fit(
    X_train_pad,
    y_train,
    validation_data=(X_val_pad, y_val),
    epochs=20,
    batch_size=64,
    callbacks=[early_stopping],
    verbose=1
)

"""Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªØ¯Ø±ÙŠØ¨

Training accuracy Ø§Ø±ØªÙØ¹Øª Ø¨Ø³Ø±Ø¹Ø© ÙˆÙˆØµÙ„Øª â‰ˆ 91%

Validation accuracy ØªÙˆÙ‚ÙØª ØªÙ‚Ø±ÙŠØ¨Ù‹Ø§ Ø¨ÙŠÙ† 70% â€“ 71%

Validation loss Ø¨Ø¯Ø£ ÙŠØ±ØªÙØ¹ Ø¨Ø¹Ø¯ Epoch 2â€“3

ğŸ“Œ Ø§Ù„Ø§Ø³ØªÙ†ØªØ§Ø¬ Ù‡Ù†Ø§

Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙŠØªØ¹Ù„Ù‘Ù… Ø¨Ø³Ø±Ø¹Ø© Ù…Ù† Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ØŒ Ù„ÙƒÙ† ÙŠØ¨Ø¯Ø£ overfitting Ù…Ø¨ÙƒÙ‘Ø±Ù‹Ø§
(ÙŠØ¹Ù†ÙŠ Ø­ÙØ¸ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø£ÙƒØ«Ø± Ù…Ù† Ø§Ù„ØªØ¹Ù…ÙŠÙ…).
"""

test_loss, test_acc = model_cnn_adv.evaluate(X_test_pad, y_test)
print("Advanced CNN Test Accuracy:", test_acc)
y_pred = model_cnn_adv.predict(X_test_pad)
y_pred = y_pred.argmax(axis=1)
print(classification_report(y_test, y_pred, digits=2))

"""Test Accuracy â‰ˆ 70.45%

Ù‡Ø°Ù‡ Ø£Ø¹Ù„Ù‰ Ø¯Ù‚Ø© ÙˆØµÙ„ØªÙŠ Ù„Ù‡Ø§ Ù…Ø¹ CNN Ù„Ø­Ø¯ Ø§Ù„Ø¢Ù†
Ø§Ù„ÙØ¦Ø§Øª Ø§Ù„ÙƒØ¨ÙŠØ±Ø© (Ù…Ø«Ù„ 1ØŒ 2ØŒ 3ØŒ 6ØŒ 10ØŒ 11):

Precision Ùˆ Recall Ø¬ÙŠØ¯ÙŠÙ†

F1-score Ù…Ø±ØªÙØ¹ Ù†Ø³Ø¨ÙŠÙ‹Ø§

Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ù…ØªØ§Ø² ÙÙŠ Ø§Ù„ÙØ¦Ø§Øª Ø°Ø§Øª Ø§Ù„Ø¹ÙŠÙ†Ø§Øª Ø§Ù„ÙƒØ«ÙŠØ±Ø©
ÙØ¦Ø§Øª Ù…Ø«Ù„: 7ØŒ 12ØŒ 14

Precision = 0

Recall = 0

ÙŠØ¹Ù†ÙŠ:

Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù„Ù… ÙŠØªÙ†Ø¨Ø£ ÙˆÙ„Ø§ Ù…Ø±Ø© Ø¨Ù‡Ø°Ù‡ Ø§Ù„ÙØ¦Ø§Øª

## ğŸ”¹ Ù†Ù…ÙˆØ°Ø¬ CNN Ù…Ø¹ FastText Embeddings

ÙÙŠ Ù‡Ø°Ù‡ Ø§Ù„ØªØ¬Ø±Ø¨Ø© Ù†Ø³ØªØ®Ø¯Ù… ØªÙ…Ø«ÙŠÙ„Ø§Øª Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ø¬Ø§Ù‡Ø²Ø© **FastText Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© (cc.ar.300.vec)** Ø¨Ø¯Ù„ ØªØ¹Ù„Ù‘Ù… Ø§Ù„Ù€ embeddings Ù…Ù† Ø§Ù„ØµÙØ±.  
FastText ÙŠØªÙ…ÙŠØ² Ø¨Ù‚Ø¯Ø±ØªÙ‡ Ø¹Ù„Ù‰ ØªÙ…Ø«ÙŠÙ„ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù†Ø§Ø¯Ø±Ø© ÙˆØ§Ù„Ù…Ø´ØªÙ‚Ø© Ù„ØºÙˆÙŠÙ‹Ø§ Ø¨Ø´ÙƒÙ„ Ø£ÙØ¶Ù„ØŒ ÙˆÙ‡Ùˆ Ù…Ù†Ø§Ø³Ø¨ Ø¬Ø¯Ù‹Ø§ Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©.

### Ø®Ø·ÙˆØ§Øª Ø§Ù„Ø¹Ù…Ù„:
1. ØªØ­Ù…ÙŠÙ„ Ù…ØªØ¬Ù‡Ø§Øª FastText Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ù…Ø³Ø¨Ù‚Ø© Ø§Ù„ØªØ¯Ø±ÙŠØ¨ (300 Ø¨Ø¹Ø¯).
2. Ø¨Ù†Ø§Ø¡ `embedding_matrix` Ø¨Ø­ÙŠØ«:
   - ÙƒÙ„ ÙƒÙ„Ù…Ø© ÙÙŠ `tokenizer.word_index` ØªØ£Ø®Ø° Ø§Ù„Ù…ØªØ¬Ù‡ Ø§Ù„Ù…Ù‚Ø§Ø¨Ù„ Ù„Ù‡Ø§ Ø¥Ù† ÙˆÙØ¬Ø¯.
   - Ø§Ù„ÙƒÙ„Ù…Ø§Øª ØºÙŠØ± Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ FastText ØªØ£Ø®Ø° Ù…ØªØ¬Ù‡ ØµÙØ±ÙŠ.
3. Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø·Ø¨Ù‚Ø© `Embedding` Ø¨Ø§Ù„Ø£ÙˆØ²Ø§Ù† Ø§Ù„Ø¬Ø§Ù‡Ø²Ø© Ù…Ø¹ `trainable=False` Ù„Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ù„ØºÙˆÙŠØ©.
4. ØªÙ…Ø±ÙŠØ± Ø§Ù„Ù€ embeddings Ø¥Ù„Ù‰ Ø·Ø¨Ù‚Ø© **Conv1D** Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ù…Ø­Ù„ÙŠØ© (n-grams).
5. Ø§Ø³ØªØ®Ø¯Ø§Ù… **GlobalMaxPooling1D** Ù„Ø§Ø®ØªÙŠØ§Ø± Ø£Ù‡Ù… Ø§Ù„Ù…ÙŠØ²Ø§Øª.
6. Ø·Ø¨Ù‚Ø§Øª Dense Ù„Ø¥Ø¬Ø±Ø§Ø¡ Ø§Ù„ØªØµÙ†ÙŠÙ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ.
"""

!wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ar.300.vec.gz
!gunzip cc.ar.300.vec.gz

EMBEDDING_DIM = 300
embedding_index = {}

with open("cc.ar.300.vec", encoding="utf-8") as f:
    for line in f:
        values = line.rstrip().split(" ")
        word = values[0]
        vector = np.asarray(values[1:], dtype="float32")
        embedding_index[word] = vector

print("Ø¹Ø¯Ø¯ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…Ø­Ù…Ù„Ø©:", len(embedding_index))

word_index = tokenizer.word_index
num_words = min(MAX_WORDS, len(word_index) + 1)

embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))

for word, i in word_index.items():
    if i >= num_words:
        continue
    vector = embedding_index.get(word)
    if vector is not None:
        embedding_matrix[i] = vector

model_cnn_ft = Sequential([
    Embedding(
        input_dim=num_words,
        output_dim=EMBEDDING_DIM,
        weights=[embedding_matrix],
        input_length=MAX_LEN,
        trainable=False   # Ù…Ù‡Ù…
    ),
    Conv1D(128, 5, activation='relu'),
    GlobalMaxPooling1D(),
    Dropout(0.5),
    Dense(128, activation='relu'),
    Dense(16, activation='softmax')
])

model_cnn_ft.compile(
    loss='sparse_categorical_crossentropy',
    optimizer='adam',
    metrics=['accuracy']
)

history_cnn_ft = model_cnn_ft.fit(
    X_train_pad, y_train,
    validation_data=(X_val_pad, y_val),
    epochs=10,
    batch_size=64
)

test_loss, test_acc = model_cnn_ft.evaluate(X_test_pad, y_test)
print("CNN + FastText Test Accuracy:", test_acc)
y_pred = model_cnn_ft.predict(X_test_pad)
y_pred_classes = y_pred.argmax(axis=1)

print(classification_report(y_test, y_pred_classes))

cm = confusion_matrix(y_test, y_pred_classes)

plt.figure(figsize=(10, 8))
sns.heatmap(
    cm,
    cmap="Blues",
    xticklabels=range(num_classes),
    yticklabels=range(num_classes),
    annot=False
)

plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.title("Confusion Matrix - CNN with FastText Embeddings")
plt.show()

"""###  Ø£Ø¯Ø§Ø¡ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ ÙˆØ§Ù„ØªØ­Ù‚Ù‚ (Training / Validation)
- Ø¨Ø¯Ø£ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ø¯Ù‚Ø© ØªØ¯Ø±ÙŠØ¨ Ù…Ù†Ø®ÙØ¶Ø© (~33%)ØŒ ÙˆÙ‡Ùˆ Ø£Ù…Ø± Ø·Ø¨ÙŠØ¹ÙŠ Ø¹Ù†Ø¯ Ø§Ø³ØªØ®Ø¯Ø§Ù… embeddings Ø«Ø§Ø¨ØªØ©.
- Ø§Ø±ØªÙØ¹Øª Ø¯Ù‚Ø© Ø§Ù„ØªØ­Ù‚Ù‚ Ø¨Ø³Ø±Ø¹Ø© Ù„ØªØµÙ„ Ø¥Ù„Ù‰ Ø­ÙˆØ§Ù„ÙŠ **69%**.
- Ø§Ù„ÙØ¬ÙˆØ© Ø¨ÙŠÙ† Ø¯Ù‚Ø© Ø§Ù„ØªØ¯Ø±ÙŠØ¨ ÙˆØ§Ù„ØªØ­Ù‚Ù‚ ØµØºÙŠØ±Ø© â†’ **Ù„Ø§ ÙŠÙˆØ¬Ø¯ overfitting ÙˆØ§Ø¶Ø­**.
- Ø«Ø¨Ø§Øª `val_loss` ÙÙŠ Ø§Ù„Ù…Ø±Ø§Ø­Ù„ Ø§Ù„Ø£Ø®ÙŠØ±Ø© ÙŠØ¯Ù„ Ø¹Ù„Ù‰ ÙˆØµÙˆÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¥Ù„Ù‰ Ø­Ø¯ÙˆØ¯Ù‡ Ø§Ù„Ø­Ø§Ù„ÙŠØ©.

###  Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± (Test Set)
- **Test Accuracy â‰ˆ 68.5%**
- Ø§Ù„Ø£Ø¯Ø§Ø¡ Ù‚Ø±ÙŠØ¨ Ø¬Ø¯Ù‹Ø§ Ù…Ù† Ø¯Ù‚Ø© Ø§Ù„ØªØ­Ù‚Ù‚ØŒ ÙˆÙ‡Ø°Ø§ Ù…Ø¤Ø´Ø± Ø¬ÙŠØ¯ Ø¹Ù„Ù‰ Ø§Ù„ØªØ¹Ù…ÙŠÙ….

### ØªØ­Ù„ÙŠÙ„ ØªÙ‚Ø±ÙŠØ± Ø§Ù„ØªØµÙ†ÙŠÙ (Classification Report)
- Ø§Ù„ÙØ¦Ø§Øª Ø°Ø§Øª Ø§Ù„Ø¯Ø¹Ù… Ø§Ù„ÙƒØ¨ÙŠØ± (Ù…Ø«Ù„ 1ØŒ 2ØŒ 10ØŒ 11) Ø­Ù‚Ù‚Øª:
  - Precision Ùˆ Recall Ù…Ø±ØªÙØ¹ÙŠÙ†
  - F1-score Ø¬ÙŠØ¯ (â‰ˆ 0.7 â€“ 0.8)
- Ø§Ù„ÙØ¦Ø§Øª Ø°Ø§Øª Ø§Ù„Ø¹ÙŠÙ†Ø§Øª Ø§Ù„Ù‚Ù„ÙŠÙ„Ø© (Ù…Ø«Ù„ 7ØŒ 12ØŒ 14):
  - Recall Ø¶Ø¹ÙŠÙ Ø£Ùˆ ØµÙØ±
  - Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù„Ù… ÙŠØªØ¹Ù„Ù… ØªÙ…Ø«ÙŠÙ„Ù‡Ø§ Ø¬ÙŠØ¯Ù‹Ø§ Ø¨Ø³Ø¨Ø¨ **Ø¹Ø¯Ù… ØªÙˆØ§Ø²Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª**

###  Macro vs Weighted Average
- **Macro Avg â‰ˆ 0.48**
  - ÙŠØªØ£Ø«Ø± Ø¨Ø§Ù„ÙØ¦Ø§Øª Ø§Ù„ØµØºÙŠØ±Ø© Ø¬Ø¯Ù‹Ø§
- **Weighted Avg â‰ˆ 0.67**
  - ÙŠØ¹Ø·ÙŠ ØµÙˆØ±Ø© Ø£Ø¯Ù‚ Ø¹Ù† Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ Ø¹Ù„Ù‰ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª

## Multi-Kernel CNN +FastText
"""

inputs = Input(shape=(MAX_LEN,))

embedding = Embedding(
    input_dim=num_words,
    output_dim=300,
    weights=[embedding_matrix],
    input_length=MAX_LEN,
    trainable=False
)(inputs)

x = SpatialDropout1D(0.3)(embedding)

# Multi-Kernel CNN
conv_3 = Conv1D(128, 3, activation='relu', padding='valid')(x)
conv_4 = Conv1D(128, 4, activation='relu', padding='valid')(x)
conv_5 = Conv1D(128, 5, activation='relu', padding='valid')(x)

pool_3 = GlobalMaxPooling1D()(conv_3)
pool_4 = GlobalMaxPooling1D()(conv_4)
pool_5 = GlobalMaxPooling1D()(conv_5)

x = Concatenate()([pool_3, pool_4, pool_5])

x = BatchNormalization()(x)
x = Dense(256, activation='relu')(x)
x = Dropout(0.5)(x)

outputs = Dense(num_classes, activation='softmax')(x)

model_mk_ft = Model(inputs, outputs)

model_mk_ft.compile(
    optimizer=Adam(learning_rate=1e-3),
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy'])

history_mk_ft = model_mk_ft.fit(
    X_train_pad,
    y_train,
    validation_data=(X_val_pad, y_val),
    epochs=15,
    batch_size=64,
    callbacks=[early_stopping],
    verbose=1
)

test_loss, test_acc = model_mk_ft.evaluate(X_test_pad, y_test, verbose=0)
print("Multi-Kernel + FastText Test Accuracy:", test_acc)
y_pred = model_mk_ft.predict(X_test_pad)
y_pred_classes = y_pred.argmax(axis=1)

print(classification_report(y_test, y_pred_classes, zero_division=0))

"""### Ø£Ø¯Ø§Ø¡ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ ÙˆØ§Ù„ØªØ­Ù‚Ù‚ (Training / Validation)
- Ø¨Ø¯Ø£ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ø¯Ù‚Ø© ØªØ¯Ø±ÙŠØ¨ Ø­ÙˆØ§Ù„ÙŠ 71.04% ÙÙŠ epoch 1ØŒ ÙˆØ§Ø±ØªÙØ¹Øª ØªØ¯Ø±ÙŠØ¬ÙŠÙ‹Ø§ Ù„ØªØµÙ„ Ø¥Ù„Ù‰ 74.47% ÙÙŠ epoch 4.
- Ø¯Ù‚Ø© Ø§Ù„ØªØ­Ù‚Ù‚ ÙƒØ§Ù†Øª Ø«Ø§Ø¨ØªØ© Ø­ÙˆÙ„ 69% Ù…Ø¹ Ø¨Ø¹Ø¶ Ø§Ù„ØªÙ‚Ù„Ø¨Ø§ØªØŒ Ù…Ù…Ø§ ÙŠØ¯Ù„ Ø¹Ù„Ù‰ Ø£Ù† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù„Ù… ÙŠØªØ¹Ù„Ù… Ø¨Ø´ÙƒÙ„ ÙƒØ§ÙÙ Ù„ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø¹Ù„Ù‰ Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„ØªØ­Ù‚Ù‚.
- Ø§Ù„ÙØ¬ÙˆØ© Ø¨ÙŠÙ† Ø¯Ù‚Ø© Ø§Ù„ØªØ¯Ø±ÙŠØ¨ ÙˆØ§Ù„ØªØ­Ù‚Ù‚ ØµØºÙŠØ±Ø© Ù†Ø³Ø¨ÙŠÙ‹Ø§ØŒ Ù…Ù…Ø§ ÙŠØ´ÙŠØ± Ø¥Ù„Ù‰ Ø¹Ø¯Ù… ÙˆØ¬ÙˆØ¯ overfitting ÙˆØ§Ø¶Ø­.
- Ø«Ø¨Ø§Øª val_loss ÙÙŠ Ø§Ù„Ù…Ø±Ø§Ø­Ù„ Ø§Ù„Ø£Ø®ÙŠØ±Ø© ÙŠØ¯Ù„ Ø¹Ù„Ù‰ ÙˆØµÙˆÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¥Ù„Ù‰ Ø­Ø¯ÙˆØ¯Ù‡ Ø§Ù„Ø­Ø§Ù„ÙŠØ©.

### Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± (Test Set)
- Test Accuracy â‰ˆ 68.39%
- Ø§Ù„Ø£Ø¯Ø§Ø¡ Ù‚Ø±ÙŠØ¨ Ø¬Ø¯Ù‹Ø§ Ù…Ù† Ø¯Ù‚Ø© Ø§Ù„ØªØ­Ù‚Ù‚ØŒ ÙˆÙ‡Ø°Ø§ Ù…Ø¤Ø´Ø± Ø¬ÙŠØ¯ Ø¹Ù„Ù‰ Ù‚Ø¯Ø±Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¹Ù„Ù‰ Ø§Ù„ØªØ¹Ù…ÙŠÙ….

### ØªØ­Ù„ÙŠÙ„ ØªÙ‚Ø±ÙŠØ± Ø§Ù„ØªØµÙ†ÙŠÙ (Classification Report)
- Ø§Ù„ÙØ¦Ø§Øª Ø°Ø§Øª Ø§Ù„Ø¯Ø¹Ù… Ø§Ù„ÙƒØ¨ÙŠØ± (Ù…Ø«Ù„ 1ØŒ 2ØŒ 10ØŒ 11) Ø­Ù‚Ù‚Øª:
  - Precision Ùˆ Recall Ù…Ø±ØªÙØ¹ÙŠÙ†
  - F1-score Ø¬ÙŠØ¯ (â‰ˆ 0.7 â€“ 0.8)
- Ø§Ù„ÙØ¦Ø§Øª Ø°Ø§Øª Ø§Ù„Ø¹ÙŠÙ†Ø§Øª Ø§Ù„Ù‚Ù„ÙŠÙ„Ø© (Ù…Ø«Ù„ 7ØŒ 12ØŒ 14):
  - Recall Ø¶Ø¹ÙŠÙ Ø£Ùˆ ØµÙØ±
  - Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù„Ù… ÙŠØªØ¹Ù„Ù… ØªÙ…Ø«ÙŠÙ„Ù‡Ø§ Ø¬ÙŠØ¯Ù‹Ø§ Ø¨Ø³Ø¨Ø¨ Ø¹Ø¯Ù… ØªÙˆØ§Ø²Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª.

### Macro vs Weighted Average
- Macro Avg â‰ˆ 0.52
  - ÙŠØªØ£Ø«Ø± Ø¨Ø§Ù„ÙØ¦Ø§Øª Ø§Ù„ØµØºÙŠØ±Ø© Ø¬Ø¯Ù‹Ø§.
- Weighted Avg â‰ˆ 0.66
  - ÙŠØ¹Ø·ÙŠ ØµÙˆØ±Ø© Ø£Ø¯Ù‚ Ø¹Ù† Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ Ø¹Ù„Ù‰ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª.

#Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ø«Ø§Ù„Ø«Ø©
"""

from datasets import Dataset
from transformers import (
    AutoTokenizer,
    AutoModelForSequenceClassification,
    Trainer,
    TrainingArguments,
    EarlyStoppingCallback
)
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import accuracy_score, f1_score

train_ds = Dataset.from_pandas(train_df[['trimmed_question', 'label']])
val_ds   = Dataset.from_pandas(val_df[['trimmed_question', 'label']])
test_ds  = Dataset.from_pandas(test_df[['trimmed_question', 'label']])

label_encoder = LabelEncoder()

train_labels = label_encoder.fit_transform(train_df['label'])
val_labels   = label_encoder.transform(val_df['label'])
test_labels  = label_encoder.transform(test_df['label'])

train_ds = train_ds.map(lambda x, i: {'label': train_labels[i]}, with_indices=True)
val_ds   = val_ds.map(lambda x, i: {'label': val_labels[i]}, with_indices=True)
test_ds  = test_ds.map(lambda x, i: {'label': test_labels[i]}, with_indices=True)

num_labels = len(label_encoder.classes_)
print("Number of classes:", num_labels)

model_name = "aubmindlab/bert-base-arabertv2"

tokenizer = AutoTokenizer.from_pretrained(model_name)

model = AutoModelForSequenceClassification.from_pretrained(
    model_name,
    num_labels=num_labels
)

"""**AraBERT v2:** Ù†Ù…ÙˆØ°Ø¬ BERT Ù…Ø¯Ø±Ø¨ Ø¹Ù„Ù‰ Ù†ØµÙˆØµ Ø¹Ø±Ø¨ÙŠØ©

**Tokenizer:** ÙŠØ­ÙˆÙ„ Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ Ø£Ø±Ù‚Ø§Ù… (Token IDs) ÙŠÙÙ‡Ù…Ù‡Ø§ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬

**AutoModelForSequenceClassification:** Ù†Ø³Ø®Ø© Ù…Ù† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…ÙÙ‡ÙŠØ£Ø© Ù„Ù„ØªØµÙ†ÙŠÙ
"""

def tokenize(batch):
    return tokenizer(
        batch["trimmed_question"],
        padding="max_length",
        truncation=True,
        max_length=128
    )

train_ds = train_ds.map(tokenize, batched=True)
val_ds   = val_ds.map(tokenize, batched=True)
test_ds  = test_ds.map(tokenize, batched=True)

"""
- **Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª**: ØªØ£Ø®Ø° Ø§Ù„Ø¯Ø§Ù„Ø© tokenize Ø¯ÙØ¹Ø© Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (batch) ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø¹Ù…ÙˆØ¯ ÙŠØ³Ù…Ù‰ "trimmed_question".
- **Ø§Ù„ØªÙˆÙƒÙ†ÙŠØ²Ø±**: ÙŠØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù… tokenizer Ù„ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†ØµÙˆØµ Ø¥Ù„Ù‰ ØªÙ…Ø«ÙŠÙ„ Ø¹Ø¯Ø¯ÙŠ ÙŠÙ…ÙƒÙ† Ù„Ù„Ù†Ù…ÙˆØ°Ø¬ ÙÙ‡Ù…Ù‡.
- **Ø§Ù„Ù…Ø¹Ù„Ù…Ø§Øª**:
  - padding="max_length": ÙŠØ¶Ù…Ù† Ø£Ù† Ø¬Ù…ÙŠØ¹ Ø§Ù„ØªÙˆÙƒÙ†Ø§Øª ØªÙƒÙˆÙ† Ø¨Ù†ÙØ³ Ø§Ù„Ø·ÙˆÙ„ (128 ØªÙˆÙƒÙ† ÙÙŠ Ù‡Ø°Ù‡ Ø§Ù„Ø­Ø§Ù„Ø©) Ø¹Ù† Ø·Ø±ÙŠÙ‚ Ø¥Ø¶Ø§ÙØ© padding.
  - truncation=True: ÙŠÙ‚ÙˆÙ… Ø¨Ù‚Øµ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„ØªÙŠ ØªØªØ¬Ø§ÙˆØ² Ø§Ù„Ø·ÙˆÙ„ Ø§Ù„Ø£Ù‚ØµÙ‰ Ø§Ù„Ù…Ø­Ø¯Ø¯ (128 ØªÙˆÙƒÙ†).
  - max_length=128: ÙŠØ­Ø¯Ø¯ Ø§Ù„Ø·ÙˆÙ„ Ø§Ù„Ø£Ù‚ØµÙ‰ Ù„Ù„ØªÙˆÙƒÙ†Ø§Øª.


"""

train_ds.set_format("torch", columns=["input_ids", "attention_mask", "label"])
val_ds.set_format("torch", columns=["input_ids", "attention_mask", "label"])
test_ds.set_format("torch", columns=["input_ids", "attention_mask", "label"])

def compute_metrics(pred):
    labels = pred.label_ids
    preds = pred.predictions.argmax(-1)

    acc = accuracy_score(labels, preds)
    f1  = f1_score(labels, preds, average="weighted")

    return {
        "accuracy": acc,
        "f1": f1
    }

"""## Ø¯Ø§Ù„Ø© compute_metrics

ØªÙ‚ÙˆÙ… Ø¯Ø§Ù„Ø© compute_metrics Ø¨Ø­Ø³Ø§Ø¨ Ø¯Ù‚ØªÙŠÙ† Ù„Ù„Ù†Ù…ÙˆØ°Ø¬: Ø§Ù„Ø¯Ù‚Ø© ÙˆØ¯Ø±Ø¬Ø© F1


## Ø§Ù„Ù…Ø®Ø±Ø¬Ø§Øª
- **Ø§Ù„Ø¯Ù‚Ø©**: Ù†Ø³Ø¨Ø© Ø§Ù„ØªÙˆÙ‚Ø¹Ø§Øª Ø§Ù„ØµØ­ÙŠØ­Ø©.
- **Ø¯Ø±Ø¬Ø© F1**: Ù…Ù‚ÙŠØ§Ø³ ÙŠÙˆØ§Ø²Ù† Ø¨ÙŠÙ† Ø§Ù„Ø¯Ù‚Ø© ÙˆØ§Ù„Ø§Ø³ØªØ±Ø¬Ø§Ø¹.


"""

training_args = TrainingArguments(
    output_dir="./arabert-cpu",
    eval_strategy="epoch",
    save_strategy="epoch",
    learning_rate=2e-5,
    per_device_train_batch_size=8,
    per_device_eval_batch_size=8,
    num_train_epochs=3,
    weight_decay=0.01,
    logging_steps=100,
    report_to="none",
    load_best_model_at_end=True,
    metric_for_best_model="eval_f1",
    greater_is_better=True
)

"""
- **Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬**: Ø³ÙŠØªÙ… Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙÙŠ Ù…Ø¬Ù„Ø¯ Ù…Ø­Ø¯Ø¯ Ø¨Ø¹Ø¯ ÙƒÙ„ ÙØªØ±Ø© ØªØ¯Ø±ÙŠØ¨.
- **Ø§Ù„ØªÙ‚ÙŠÙŠÙ…**: Ø³ÙŠØªÙ… ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ø¹Ø¯ ÙƒÙ„ ÙØªØ±Ø© ØªØ¯Ø±ÙŠØ¨.
- **Ù…Ø¹Ø¯Ù„ Ø§Ù„ØªØ¹Ù„Ù…**: Ù‚ÙŠÙ…Ø© ØµØºÙŠØ±Ø© Ù„Ù„ØªØ­ÙƒÙ… ÙÙŠ Ø³Ø±Ø¹Ø© Ø§Ù„ØªØ¹Ù„Ù….
- **Ø­Ø¬Ù… Ø§Ù„Ø¯ÙØ¹Ø©**: Ø¹Ø¯Ø¯ Ø§Ù„Ø¹ÙŠÙ†Ø§Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© ÙÙŠ ÙˆÙ‚Øª ÙˆØ§Ø­Ø¯ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ ÙˆØ§Ù„ØªÙ‚ÙŠÙŠÙ….
- **Ø¹Ø¯Ø¯ Ø§Ù„ÙØªØ±Ø§Øª**: Ø³ÙŠØªÙ… ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù„Ø«Ù„Ø§Ø« ÙØªØ±Ø§Øª.
- **Ø§Ù„Ø§Ù†Ø­Ø¯Ø§Ø±**: ÙŠØ³ØªØ®Ø¯Ù… Ù„ØªÙ‚Ù„ÙŠÙ„ Ø§Ù„Ø¥ÙØ±Ø§Ø· ÙÙŠ Ø§Ù„ØªÙƒÙŠÙ.
- **ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª**: Ø³ÙŠØªÙ… ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª ÙƒÙ„ 100 Ø®Ø·ÙˆØ©.
- **Ø§Ø®ØªÙŠØ§Ø± Ø£ÙØ¶Ù„ Ù†Ù…ÙˆØ°Ø¬**: Ø³ÙŠØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø£ÙØ¶Ù„ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø¯Ø±Ø¬Ø© F1.
"""

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_ds,
    eval_dataset=val_ds,
    tokenizer=tokenizer,
    compute_metrics=compute_metrics,
    callbacks=[EarlyStoppingCallback(early_stopping_patience=1)]
)

"""
- **model**: Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø°ÙŠ Ø³ÙŠØªÙ… ØªØ¯Ø±ÙŠØ¨Ù‡.
- **args**: Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„ØªØ¯Ø±ÙŠØ¨.
- **train_dataset**: Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø© Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬.
- **eval_dataset**: Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø© Ù„ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬.
- **tokenizer**: Ø§Ù„Ø£Ø¯Ø§Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø© Ù„ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†ØµÙˆØµ Ø¥Ù„Ù‰ ØªÙ†Ø³ÙŠÙ‚ ÙŠÙ…ÙƒÙ† Ù„Ù„Ù†Ù…ÙˆØ°Ø¬ ÙÙ‡Ù…Ù‡.
- **compute_metrics**: Ø¯Ø§Ù„Ø© Ù„Ø­Ø³Ø§Ø¨ Ø§Ù„Ø£Ø¯Ø§Ø¡.
- **callbacks**: Ù‚Ø§Ø¦Ù…Ø© Ù…Ù† callbacksØŒ Ù…Ø«Ù„ EarlyStoppingCallbackØŒ Ù„Ø¥Ø¯Ø§Ø±Ø© Ø¹Ù…Ù„ÙŠØ© Ø§Ù„ØªØ¯Ø±ÙŠØ¨.
"""

trainer.train()

test_results = trainer.evaluate(test_ds)
print(test_results)

"""### Ø£Ø¯Ø§Ø¡ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ ÙˆØ§Ù„ØªØ­Ù‚Ù‚ (Training / Validation)
- Ø¨Ø¯Ø£ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ø¯Ù‚Ø© ØªØ¯Ø±ÙŠØ¨ Ø­ÙˆØ§Ù„ÙŠ 74.12% ÙÙŠ epoch 1ØŒ ÙˆØ§Ø±ØªÙØ¹Øª ØªØ¯Ø±ÙŠØ¬ÙŠÙ‹Ø§ Ù„ØªØµÙ„ Ø¥Ù„Ù‰ 76.63% ÙÙŠ epoch 3.
- Ø¯Ù‚Ø© Ø§Ù„ØªØ­Ù‚Ù‚ ÙƒØ§Ù†Øª Ø«Ø§Ø¨ØªØ© Ø­ÙˆÙ„ 75.64% Ù…Ø¹ Ø¨Ø¹Ø¶ Ø§Ù„ØªÙ‚Ù„Ø¨Ø§ØªØŒ Ù…Ù…Ø§ ÙŠØ¯Ù„ Ø¹Ù„Ù‰ Ø£Ù† Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù‚Ø¯ Ø¨Ø¯Ø£ ÙÙŠ Ø§Ù„ØªØ¹Ù„Ù… ÙˆÙ„ÙƒÙ†Ù‡ Ù„Ø§ ÙŠØ²Ø§Ù„ ÙŠØ­ØªØ§Ø¬ Ø¥Ù„Ù‰ ØªØ­Ø³ÙŠÙ†.
- Ø§Ù„ÙØ¬ÙˆØ© Ø¨ÙŠÙ† Ø¯Ù‚Ø© Ø§Ù„ØªØ¯Ø±ÙŠØ¨ ÙˆØ§Ù„ØªØ­Ù‚Ù‚ ØµØºÙŠØ±Ø© Ù†Ø³Ø¨ÙŠÙ‹Ø§ØŒ Ù…Ù…Ø§ ÙŠØ´ÙŠØ± Ø¥Ù„Ù‰ Ø¹Ø¯Ù… ÙˆØ¬ÙˆØ¯ overfitting ÙˆØ§Ø¶Ø­.
- Ø«Ø¨Ø§Øª val_loss ÙÙŠ Ø§Ù„Ù…Ø±Ø§Ø­Ù„ Ø§Ù„Ø£Ø®ÙŠØ±Ø© ÙŠØ¯Ù„ Ø¹Ù„Ù‰ ÙˆØµÙˆÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¥Ù„Ù‰ Ø­Ø¯ÙˆØ¯Ù‡ Ø§Ù„Ø­Ø§Ù„ÙŠØ©.

### Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± (Test Set)
- Test Accuracy â‰ˆ 75.64%
- Ø§Ù„Ø£Ø¯Ø§Ø¡ Ù‚Ø±ÙŠØ¨ Ø¬Ø¯Ù‹Ø§ Ù…Ù† Ø¯Ù‚Ø© Ø§Ù„ØªØ­Ù‚Ù‚ØŒ ÙˆÙ‡Ø°Ø§ Ù…Ø¤Ø´Ø± Ø¬ÙŠØ¯ Ø¹Ù„Ù‰ Ù‚Ø¯Ø±Ø© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¹Ù„Ù‰ Ø§Ù„ØªØ¹Ù…ÙŠÙ….

### Macro vs Weighted Average
- Macro Avg â‰ˆ 0.70
  - ÙŠØªØ£Ø«Ø± Ø¨Ø§Ù„ÙØ¦Ø§Øª Ø§Ù„ØµØºÙŠØ±Ø© Ø¬Ø¯Ù‹Ø§.
- Weighted Avg â‰ˆ 0.75
  - ÙŠØ¹Ø·ÙŠ ØµÙˆØ±Ø© Ø£Ø¯Ù‚ Ø¹Ù† Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ Ø¹Ù„Ù‰ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª.

#Ø¬Ø¯ÙˆÙ„ Ù…Ù‚Ø§Ø±Ù†Ø© Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„ØªØµÙ†ÙŠÙ

| Ø§Ù„Ù†Ù…ÙˆØ°Ø¬                       | Ø§Ù„Ø¯Ù‚Ø© (Train) | Ø§Ù„Ø¯Ù‚Ø© (Validation) | Ø§Ù„Ø¯Ù‚Ø© (Test) | F1-Score (Macro Avg) | F1-Score (Weighted Avg) |
|-------------------------------|---------------|---------------------|--------------|-----------------------|--------------------------|
| Logistic Regression            | 82.89%        | 72.78%              | 72.67%       | 0.59                  | 0.73                     |
| Logistic Regression Ø§Ù„Ù…Ø­Ø³Ù†     | 93.67%        | 73.72%              | 73.74%       | 0.58                  | 0.73                     |
| SVM                           | 98.66%        | 73.46%              | 72.79%       | 0.58                  | 0.73                     |
| SVM Ø§Ù„Ù…Ø­Ø³Ù†                    | 95.83%        | 74.01%              | 73.79%       | 0.59                  | 0.74                     |
| MultinomialNB                 | 68.92%        | 64.61%              | 63.63%       | 0.34                  | 0.58                     |
| ComplementNB                   | 77.99%        | 72.50%              | 71.83%       | 0.49                  | 0.69                     |
| ComplementNB Ø§Ù„Ù…Ø­Ø³Ù†            | 79.88%        | 73.08%              | 72.72%       | 0.51                  | 0.71                     |
| Random Forest                  | 63.16%        | 61.13%              | 59.88%       | 0.47                  | 0.61                     |
| LSTM                          | 87.93%        | 59.43%              | 58.61%       | 0.47                  | 0.61                     |
| BiLSTM                        | 95.60%        | 64.28%              | 64.12%       | 0.47                  | 0.61                     |
| BiLSTM Regularized Ù…Ø­Ø³Ù†       | 91.18%        | 66.44%              | 69.77%       | 0.45                  | 0.67                     |
| BiLSTM with Class Weights     | 98.61%        | 64.41%              | 62.25%       | 0.45                  | 0.67                     |
| CNN                           | 97.29%        | 69.23%              | 70.93%       | 0.48                  | 0.69                     |
| CNN + Class Weights           | 94.89%        | 68.68%              | 66.26%       | 0.52                  | 0.67                     |
| Multi-Kernel CNN              | 93.60%        | 69.95%              | 70.87%       | 0.50                  | 0.70                     |
| CNN + FastText                | 79.02%        | 69.41%              | 67.60%       | 0.48                  | 0.66                     |
| Multi-Kernel CNN + FastText   | 74.47%        | 69.05%              | 68.39%       | 0.47                  | 0.66                     |
| AraBERT v2                    | 87.12%      | 76.63%              | 75.64%       | 0.75                | 0.75                     |

#  Ø£ÙØ¶Ù„ Ù†Ù…ÙˆØ°Ø¬: AraBERT v2

1. **Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø£Ø¹Ù„Ù‰ Ù…Ø·Ù„Ù‚Ø§Ù‹:**
   - **Ø¯Ù‚Ø© Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±:** 75.64% (+1.85% Ø¹Ù† Ø«Ø§Ù†ÙŠ Ø£ÙØ¶Ù„ Ù†Ù…ÙˆØ°Ø¬)
   - **F1-Score:** 0.747 (Ø£Ø¹Ù„Ù‰ ØªÙˆØ§Ø²Ù† Ø¨ÙŠÙ† Precision Ùˆ Recall)
   - **Ø¯Ù‚Ø© Ø§Ù„ØªØ­Ù‚Ù‚:** 76.63% (Ø£ÙØ¶Ù„ ØªØ¹Ù…ÙŠÙ…)

2. **Ø£Ø³Ø¨Ø§Ø¨ Ø§Ù„ØªÙÙˆÙ‚ Ø§Ù„ØªÙ‚Ù†ÙŠØ©:**
   - **Ù…Ø¯Ø±Ø¨ Ù…Ø³Ø¨Ù‚Ø§Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©:** AraBERT Ù…ÙØ¯Ø±Ø¨ Ø¹Ù„Ù‰ 8.3 Ù…Ù„ÙŠØ§Ø± ÙƒÙ„Ù…Ø© Ø¹Ø±Ø¨ÙŠØ©.
   - **ÙÙ‡Ù… Ø§Ù„Ø³ÙŠØ§Ù‚:** ÙŠØ³ØªØ®Ø¯Ù… Transformers Ù„ÙÙ‡Ù… Ø§Ù„Ø¹Ù„Ø§Ù‚Ø§Øª Ø¨ÙŠÙ† Ø§Ù„ÙƒÙ„Ù…Ø§Øª.
   - **ØªÙ…Ø«ÙŠÙ„ ÙƒÙ„Ù…Ø§Øª Ø£ÙØ¶Ù„:** WordPiece tokenization Ù„Ù„Ø¹Ø±Ø¨ÙŠØ©.

3. **ØªØ­Ù„ÙŠÙ„ Ø£Ø¯Ø§Ø¡ Ø§Ù„ØªØ¯Ø±ÙŠØ¨:**
   | Epoch | Training Loss | Validation Accuracy | Ø§Ù„ØªØ­Ø³Ù† |
   |-------|---------------|---------------------|--------|
   | 1     | 0.995         | 74.12%              | -      |
   | 2     | 0.850         | 75.98%              | +1.86% |
   | 3     | 0.636         | 76.63%              | +0.65% |

4. **Ø§Ù„ØªØ¹Ù…ÙŠÙ… Ø§Ù„Ù…Ù…ØªØ§Ø²:**
   - **ÙØ§Ø±Ù‚ Ø·ÙÙŠÙ:** 76.63% (ØªØ­Ù‚Ù‚) â†’ 75.64% (Ø§Ø®ØªØ¨Ø§Ø±) = ÙØ§Ø±Ù‚ 0.99% ÙÙ‚Ø·.
   - **Ù…Ø¤Ø´Ø±:** Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙŠØªØ¹Ù…Ù… Ø¨Ø´ÙƒÙ„ Ù…Ù…ØªØ§Ø² Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª Ø¬Ø¯ÙŠØ¯Ø©.
"""



